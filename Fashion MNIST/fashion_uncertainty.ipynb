{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f",
   "metadata": {
    "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../birdgp\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import bird_gp_uncertainty\n",
    "import random\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16890bd2-2eb6-460a-a392-34a947a5c311",
   "metadata": {
    "id": "16890bd2-2eb6-460a-a392-34a947a5c311"
   },
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"fashion-mnist_train.csv\", skiprows = 1, delimiter = \",\")\n",
    "test_data = np.loadtxt(\"fashion-mnist_test.csv\", skiprows = 1, delimiter = \",\")\n",
    "\n",
    "train_img = train_data[:, 1:]\n",
    "test_img = test_data[:, 1:]\n",
    "train_label = train_data[:, 0]\n",
    "test_label = test_data[:, 0]\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255\n",
    "\n",
    "train_idx_all = np.arange(60000)\n",
    "test_idx_all = np.arange(10000)\n",
    "\n",
    "n = 2000\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "exp = 0\n",
    "\n",
    "random.seed(exp)\n",
    "torch.manual_seed(exp)\n",
    "np.random.seed(exp)\n",
    "\n",
    "#####################################################################\n",
    "# generate images\n",
    "train_idx = np.random.choice(train_idx_all, size = n_train, replace = False)\n",
    "test_idx = np.random.choice(test_idx_all, size = n_test, replace = False)\n",
    "\n",
    "train_imgs = train_img[train_idx, ]\n",
    "test_imgs = test_img[test_idx, ]\n",
    "train_lbs = train_label[train_idx]\n",
    "test_lbs = test_label[test_idx]\n",
    "\n",
    "train_quantiles = np.zeros((4, n_train))\n",
    "for i in range(n_train):\n",
    "    train_img_i = train_imgs[i, :]\n",
    "    train_img_i = train_img_i[train_img_i > 0]\n",
    "    train_quantiles[:, i] = np.quantile(train_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "train_q0 = np.tile(train_quantiles[0, :].reshape((n_train, 1)), (1, 784))\n",
    "train_q1 = np.tile(train_quantiles[1, :].reshape((n_train, 1)), (1, 784))\n",
    "train_q2 = np.tile(train_quantiles[2, :].reshape((n_train, 1)), (1, 784))\n",
    "train_q3 = np.tile(train_quantiles[3, :].reshape((n_train, 1)), (1, 784))\n",
    "\n",
    "train_p0 = np.zeros((n_train, 784))\n",
    "train_p1 = np.zeros((n_train, 784))\n",
    "train_p2 = np.zeros((n_train, 784))\n",
    "train_p3 = np.zeros((n_train, 784))\n",
    "\n",
    "train_p3[train_imgs >= train_q3] = train_imgs[train_imgs >= train_q3]\n",
    "train_p2[(train_imgs >= train_q2) & (train_imgs < train_q3)] = train_imgs[(train_imgs >= train_q2) & (train_imgs < train_q3)]\n",
    "train_p1[(train_imgs >= train_q1) & (train_imgs < train_q2)] = train_imgs[(train_imgs >= train_q1) & (train_imgs < train_q2)]\n",
    "train_p0[(train_imgs >= train_q0) & (train_imgs < train_q1)] = train_imgs[(train_imgs >= train_q0) & (train_imgs < train_q1)]\n",
    "\n",
    "train_predictors = np.zeros((n_train, 28*28*4))\n",
    "train_outcomes = train_imgs\n",
    "for i in range(n_train):\n",
    "    train_p0_i = train_p0[i, :].reshape((28, 28))\n",
    "    train_p1_i = train_p1[i, :].reshape((28, 28))\n",
    "    train_p2_i = train_p2[i, :].reshape((28, 28))\n",
    "    train_p3_i = train_p3[i, :].reshape((28, 28))\n",
    "    train_predictor_i = np.hstack((train_p0_i, train_p1_i, train_p2_i, train_p3_i))\n",
    "    train_predictors[i, :] = train_predictor_i.reshape(-1)\n",
    "\n",
    "test_quantiles = np.zeros((4, n_test))\n",
    "for i in range(n_test):\n",
    "    test_img_i = test_imgs[i, :]\n",
    "    test_img_i = test_img_i[test_img_i > 0]\n",
    "    test_quantiles[:, i] = np.quantile(test_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "test_q0 = np.tile(test_quantiles[0, :].reshape((n_test, 1)), (1, 784))\n",
    "test_q1 = np.tile(test_quantiles[1, :].reshape((n_test, 1)), (1, 784))\n",
    "test_q2 = np.tile(test_quantiles[2, :].reshape((n_test, 1)), (1, 784))\n",
    "test_q3 = np.tile(test_quantiles[3, :].reshape((n_test, 1)), (1, 784))\n",
    "\n",
    "test_p0 = np.zeros((n_test, 784))\n",
    "test_p1 = np.zeros((n_test, 784))\n",
    "test_p2 = np.zeros((n_test, 784))\n",
    "test_p3 = np.zeros((n_test, 784))\n",
    "\n",
    "test_p3[test_imgs >= test_q3] = test_imgs[test_imgs >= test_q3]\n",
    "test_p2[(test_imgs >= test_q2) & (test_imgs < test_q3)] = test_imgs[(test_imgs >= test_q2) & (test_imgs < test_q3)]\n",
    "test_p1[(test_imgs >= test_q1) & (test_imgs < test_q2)] = test_imgs[(test_imgs >= test_q1) & (test_imgs < test_q2)]\n",
    "test_p0[(test_imgs >= test_q0) & (test_imgs < test_q1)] = test_imgs[(test_imgs >= test_q0) & (test_imgs < test_q1)]\n",
    "\n",
    "test_predictors = np.zeros((n_test, 28*28*4))\n",
    "test_outcomes = test_imgs\n",
    "for i in range(n_test):\n",
    "    test_p0_i = test_p0[i, :].reshape((28, 28))\n",
    "    test_p1_i = test_p1[i, :].reshape((28, 28))\n",
    "    test_p2_i = test_p2[i, :].reshape((28, 28))\n",
    "    test_p3_i = test_p3[i, :].reshape((28, 28))\n",
    "    test_predictor_i = np.hstack((test_p0_i, test_p1_i, test_p2_i, test_p3_i))\n",
    "    test_predictors[i, :] = test_predictor_i.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c87c9-1422-4d5d-9f9d-35fcd77895f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "a56c87c9-1422-4d5d-9f9d-35fcd77895f7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2d93e5ae-6072-4432-fbd4-bf5efe6cd7a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit basis for predictors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [09:09<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basis orthogonalization ...\n",
      "fit basis for outcomes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:28<00:00, 67.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basis orthogonalization ...\n",
      "fit basis coefficients for predictors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:17<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit basis coefficients for outcomes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:08<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stein variation gradient descent ...\n",
      "epoch: 1 / 700, training rmse: 1.638, training r2: 0.097\n",
      "epoch: 2 / 700, training rmse: 1.5536, training r2: 0.1877\n",
      "epoch: 3 / 700, training rmse: 1.4749, training r2: 0.2678\n",
      "epoch: 4 / 700, training rmse: 1.401, training r2: 0.3394\n",
      "epoch: 5 / 700, training rmse: 1.3328, training r2: 0.4021\n",
      "epoch: 6 / 700, training rmse: 1.2697, training r2: 0.4574\n",
      "epoch: 7 / 700, training rmse: 1.2114, training r2: 0.5061\n",
      "epoch: 8 / 700, training rmse: 1.1578, training r2: 0.5489\n",
      "epoch: 9 / 700, training rmse: 1.109, training r2: 0.5861\n",
      "epoch: 10 / 700, training rmse: 1.0645, training r2: 0.6186\n",
      "epoch: 11 / 700, training rmse: 1.0253, training r2: 0.6462\n",
      "epoch: 12 / 700, training rmse: 0.9889, training r2: 0.6709\n",
      "epoch: 13 / 700, training rmse: 0.9569, training r2: 0.6918\n",
      "epoch: 14 / 700, training rmse: 0.928, training r2: 0.7101\n",
      "epoch: 15 / 700, training rmse: 0.903, training r2: 0.7256\n",
      "epoch: 16 / 700, training rmse: 0.8801, training r2: 0.7393\n",
      "epoch: 17 / 700, training rmse: 0.8601, training r2: 0.751\n",
      "epoch: 18 / 700, training rmse: 0.8419, training r2: 0.7615\n",
      "epoch: 19 / 700, training rmse: 0.8255, training r2: 0.7706\n",
      "epoch: 20 / 700, training rmse: 0.8105, training r2: 0.7789\n",
      "epoch: 21 / 700, training rmse: 0.7965, training r2: 0.7865\n",
      "epoch: 22 / 700, training rmse: 0.7835, training r2: 0.7934\n",
      "epoch: 23 / 700, training rmse: 0.7714, training r2: 0.7998\n",
      "epoch: 24 / 700, training rmse: 0.7595, training r2: 0.8059\n",
      "epoch: 25 / 700, training rmse: 0.7482, training r2: 0.8116\n",
      "epoch: 26 / 700, training rmse: 0.7372, training r2: 0.8171\n",
      "epoch: 27 / 700, training rmse: 0.7265, training r2: 0.8224\n",
      "epoch: 28 / 700, training rmse: 0.7161, training r2: 0.8274\n",
      "epoch: 29 / 700, training rmse: 0.706, training r2: 0.8322\n",
      "epoch: 30 / 700, training rmse: 0.6955, training r2: 0.8372\n",
      "epoch: 31 / 700, training rmse: 0.6859, training r2: 0.8416\n",
      "epoch: 32 / 700, training rmse: 0.6762, training r2: 0.8461\n",
      "epoch: 33 / 700, training rmse: 0.6668, training r2: 0.8504\n",
      "epoch: 34 / 700, training rmse: 0.6576, training r2: 0.8545\n",
      "epoch: 35 / 700, training rmse: 0.6487, training r2: 0.8584\n",
      "epoch: 36 / 700, training rmse: 0.6399, training r2: 0.8622\n",
      "epoch: 37 / 700, training rmse: 0.6313, training r2: 0.8659\n",
      "epoch: 38 / 700, training rmse: 0.623, training r2: 0.8694\n",
      "epoch: 39 / 700, training rmse: 0.615, training r2: 0.8727\n",
      "epoch: 40 / 700, training rmse: 0.6069, training r2: 0.876\n",
      "epoch: 41 / 700, training rmse: 0.5994, training r2: 0.8791\n",
      "epoch: 42 / 700, training rmse: 0.5921, training r2: 0.882\n",
      "epoch: 43 / 700, training rmse: 0.5846, training r2: 0.885\n",
      "epoch: 44 / 700, training rmse: 0.5779, training r2: 0.8876\n",
      "epoch: 45 / 700, training rmse: 0.5712, training r2: 0.8902\n",
      "epoch: 46 / 700, training rmse: 0.5647, training r2: 0.8927\n",
      "epoch: 47 / 700, training rmse: 0.5584, training r2: 0.8951\n",
      "epoch: 48 / 700, training rmse: 0.5525, training r2: 0.8973\n",
      "epoch: 49 / 700, training rmse: 0.5465, training r2: 0.8995\n",
      "epoch: 50 / 700, training rmse: 0.541, training r2: 0.9015\n",
      "epoch: 51 / 700, training rmse: 0.5355, training r2: 0.9035\n",
      "epoch: 52 / 700, training rmse: 0.5304, training r2: 0.9053\n",
      "epoch: 53 / 700, training rmse: 0.5254, training r2: 0.9071\n",
      "epoch: 54 / 700, training rmse: 0.5208, training r2: 0.9087\n",
      "epoch: 55 / 700, training rmse: 0.516, training r2: 0.9104\n",
      "epoch: 56 / 700, training rmse: 0.5115, training r2: 0.9119\n",
      "epoch: 57 / 700, training rmse: 0.5074, training r2: 0.9133\n",
      "epoch: 58 / 700, training rmse: 0.5034, training r2: 0.9147\n",
      "epoch: 59 / 700, training rmse: 0.4996, training r2: 0.916\n",
      "epoch: 60 / 700, training rmse: 0.4956, training r2: 0.9173\n",
      "epoch: 61 / 700, training rmse: 0.4918, training r2: 0.9186\n",
      "epoch: 62 / 700, training rmse: 0.4883, training r2: 0.9198\n",
      "epoch: 63 / 700, training rmse: 0.4851, training r2: 0.9208\n",
      "epoch: 64 / 700, training rmse: 0.4814, training r2: 0.922\n",
      "epoch: 65 / 700, training rmse: 0.4782, training r2: 0.923\n",
      "epoch: 66 / 700, training rmse: 0.4747, training r2: 0.9242\n",
      "epoch: 67 / 700, training rmse: 0.4721, training r2: 0.925\n",
      "epoch: 68 / 700, training rmse: 0.4689, training r2: 0.926\n",
      "epoch: 69 / 700, training rmse: 0.4659, training r2: 0.927\n",
      "epoch: 70 / 700, training rmse: 0.463, training r2: 0.9278\n",
      "epoch: 71 / 700, training rmse: 0.4605, training r2: 0.9286\n",
      "epoch: 72 / 700, training rmse: 0.4576, training r2: 0.9295\n",
      "epoch: 73 / 700, training rmse: 0.455, training r2: 0.9303\n",
      "epoch: 74 / 700, training rmse: 0.4529, training r2: 0.931\n",
      "epoch: 75 / 700, training rmse: 0.4498, training r2: 0.9319\n",
      "epoch: 76 / 700, training rmse: 0.4474, training r2: 0.9326\n",
      "epoch: 77 / 700, training rmse: 0.4453, training r2: 0.9333\n",
      "epoch: 78 / 700, training rmse: 0.4434, training r2: 0.9338\n",
      "epoch: 79 / 700, training rmse: 0.4412, training r2: 0.9345\n",
      "epoch: 80 / 700, training rmse: 0.4391, training r2: 0.9351\n",
      "epoch: 81 / 700, training rmse: 0.4369, training r2: 0.9358\n",
      "epoch: 82 / 700, training rmse: 0.4351, training r2: 0.9363\n",
      "epoch: 83 / 700, training rmse: 0.433, training r2: 0.9369\n",
      "epoch: 84 / 700, training rmse: 0.4312, training r2: 0.9374\n",
      "epoch: 85 / 700, training rmse: 0.429, training r2: 0.9381\n",
      "epoch: 86 / 700, training rmse: 0.4274, training r2: 0.9385\n",
      "epoch: 87 / 700, training rmse: 0.4255, training r2: 0.9391\n",
      "epoch: 88 / 700, training rmse: 0.4237, training r2: 0.9396\n",
      "epoch: 89 / 700, training rmse: 0.4222, training r2: 0.94\n",
      "epoch: 90 / 700, training rmse: 0.4204, training r2: 0.9405\n",
      "epoch: 91 / 700, training rmse: 0.4187, training r2: 0.941\n",
      "epoch: 92 / 700, training rmse: 0.4168, training r2: 0.9415\n",
      "epoch: 93 / 700, training rmse: 0.4161, training r2: 0.9417\n",
      "epoch: 94 / 700, training rmse: 0.4143, training r2: 0.9422\n",
      "epoch: 95 / 700, training rmse: 0.4123, training r2: 0.9428\n",
      "epoch: 96 / 700, training rmse: 0.4112, training r2: 0.9431\n",
      "epoch: 97 / 700, training rmse: 0.4091, training r2: 0.9437\n",
      "epoch: 98 / 700, training rmse: 0.409, training r2: 0.9437\n",
      "epoch: 99 / 700, training rmse: 0.407, training r2: 0.9443\n",
      "epoch: 100 / 700, training rmse: 0.4055, training r2: 0.9447\n",
      "epoch: 101 / 700, training rmse: 0.4044, training r2: 0.945\n",
      "epoch: 102 / 700, training rmse: 0.4028, training r2: 0.9454\n",
      "epoch: 103 / 700, training rmse: 0.4014, training r2: 0.9458\n",
      "epoch: 104 / 700, training rmse: 0.4004, training r2: 0.946\n",
      "epoch: 105 / 700, training rmse: 0.3991, training r2: 0.9464\n",
      "epoch: 106 / 700, training rmse: 0.3979, training r2: 0.9467\n",
      "epoch: 107 / 700, training rmse: 0.3964, training r2: 0.9471\n",
      "epoch: 108 / 700, training rmse: 0.3949, training r2: 0.9475\n",
      "epoch: 109 / 700, training rmse: 0.3933, training r2: 0.9479\n",
      "epoch: 110 / 700, training rmse: 0.393, training r2: 0.948\n",
      "epoch: 111 / 700, training rmse: 0.3915, training r2: 0.9484\n",
      "epoch: 112 / 700, training rmse: 0.3904, training r2: 0.9487\n",
      "epoch: 113 / 700, training rmse: 0.389, training r2: 0.9491\n",
      "epoch: 114 / 700, training rmse: 0.3881, training r2: 0.9493\n",
      "epoch: 115 / 700, training rmse: 0.3868, training r2: 0.9496\n",
      "epoch: 116 / 700, training rmse: 0.3858, training r2: 0.9499\n",
      "epoch: 117 / 700, training rmse: 0.3844, training r2: 0.9503\n",
      "epoch: 118 / 700, training rmse: 0.3836, training r2: 0.9505\n",
      "epoch: 119 / 700, training rmse: 0.3822, training r2: 0.9508\n",
      "epoch: 120 / 700, training rmse: 0.3815, training r2: 0.951\n",
      "epoch: 121 / 700, training rmse: 0.3803, training r2: 0.9513\n",
      "epoch: 122 / 700, training rmse: 0.3796, training r2: 0.9515\n",
      "epoch: 123 / 700, training rmse: 0.3788, training r2: 0.9517\n",
      "epoch: 124 / 700, training rmse: 0.3776, training r2: 0.952\n",
      "epoch: 125 / 700, training rmse: 0.3766, training r2: 0.9523\n",
      "epoch: 126 / 700, training rmse: 0.3757, training r2: 0.9525\n",
      "epoch: 127 / 700, training rmse: 0.3744, training r2: 0.9528\n",
      "epoch: 128 / 700, training rmse: 0.3739, training r2: 0.953\n",
      "epoch: 129 / 700, training rmse: 0.3726, training r2: 0.9533\n",
      "epoch: 130 / 700, training rmse: 0.3717, training r2: 0.9535\n",
      "epoch: 131 / 700, training rmse: 0.3711, training r2: 0.9536\n",
      "epoch: 132 / 700, training rmse: 0.3701, training r2: 0.9539\n",
      "epoch: 133 / 700, training rmse: 0.3688, training r2: 0.9542\n",
      "epoch: 134 / 700, training rmse: 0.3679, training r2: 0.9544\n",
      "epoch: 135 / 700, training rmse: 0.3675, training r2: 0.9545\n",
      "epoch: 136 / 700, training rmse: 0.3665, training r2: 0.9548\n",
      "epoch: 137 / 700, training rmse: 0.3655, training r2: 0.9551\n",
      "epoch: 138 / 700, training rmse: 0.3644, training r2: 0.9553\n",
      "epoch: 139 / 700, training rmse: 0.3646, training r2: 0.9553\n",
      "epoch: 140 / 700, training rmse: 0.3628, training r2: 0.9557\n",
      "epoch: 141 / 700, training rmse: 0.362, training r2: 0.9559\n",
      "epoch: 142 / 700, training rmse: 0.362, training r2: 0.9559\n",
      "epoch: 143 / 700, training rmse: 0.3605, training r2: 0.9563\n",
      "epoch: 144 / 700, training rmse: 0.3595, training r2: 0.9565\n",
      "epoch: 145 / 700, training rmse: 0.3591, training r2: 0.9566\n",
      "epoch: 146 / 700, training rmse: 0.3581, training r2: 0.9568\n",
      "epoch: 147 / 700, training rmse: 0.357, training r2: 0.9571\n",
      "epoch: 148 / 700, training rmse: 0.3569, training r2: 0.9571\n",
      "epoch: 149 / 700, training rmse: 0.3561, training r2: 0.9573\n",
      "epoch: 150 / 700, training rmse: 0.3553, training r2: 0.9575\n",
      "epoch: 151 / 700, training rmse: 0.354, training r2: 0.9578\n",
      "epoch: 152 / 700, training rmse: 0.3532, training r2: 0.958\n",
      "epoch: 153 / 700, training rmse: 0.353, training r2: 0.9581\n",
      "epoch: 154 / 700, training rmse: 0.3522, training r2: 0.9583\n",
      "epoch: 155 / 700, training rmse: 0.3511, training r2: 0.9585\n",
      "epoch: 156 / 700, training rmse: 0.3502, training r2: 0.9587\n",
      "epoch: 157 / 700, training rmse: 0.3492, training r2: 0.959\n",
      "epoch: 158 / 700, training rmse: 0.3487, training r2: 0.9591\n",
      "epoch: 159 / 700, training rmse: 0.3481, training r2: 0.9592\n",
      "epoch: 160 / 700, training rmse: 0.3474, training r2: 0.9594\n",
      "epoch: 161 / 700, training rmse: 0.3466, training r2: 0.9596\n",
      "epoch: 162 / 700, training rmse: 0.3459, training r2: 0.9597\n",
      "epoch: 163 / 700, training rmse: 0.3454, training r2: 0.9599\n",
      "epoch: 164 / 700, training rmse: 0.3449, training r2: 0.96\n",
      "epoch: 165 / 700, training rmse: 0.344, training r2: 0.9602\n",
      "epoch: 166 / 700, training rmse: 0.3429, training r2: 0.9604\n",
      "epoch: 167 / 700, training rmse: 0.3427, training r2: 0.9605\n",
      "epoch: 168 / 700, training rmse: 0.342, training r2: 0.9606\n",
      "epoch: 169 / 700, training rmse: 0.3415, training r2: 0.9608\n",
      "epoch: 170 / 700, training rmse: 0.3405, training r2: 0.961\n",
      "epoch: 171 / 700, training rmse: 0.3401, training r2: 0.9611\n",
      "epoch: 172 / 700, training rmse: 0.339, training r2: 0.9613\n",
      "epoch: 173 / 700, training rmse: 0.3387, training r2: 0.9614\n",
      "epoch: 174 / 700, training rmse: 0.3381, training r2: 0.9615\n",
      "epoch: 175 / 700, training rmse: 0.3376, training r2: 0.9616\n",
      "epoch: 176 / 700, training rmse: 0.337, training r2: 0.9618\n",
      "epoch: 177 / 700, training rmse: 0.3362, training r2: 0.9619\n",
      "epoch: 178 / 700, training rmse: 0.3355, training r2: 0.9621\n",
      "epoch: 179 / 700, training rmse: 0.3348, training r2: 0.9623\n",
      "epoch: 180 / 700, training rmse: 0.3344, training r2: 0.9624\n",
      "epoch: 181 / 700, training rmse: 0.3336, training r2: 0.9626\n",
      "epoch: 182 / 700, training rmse: 0.3334, training r2: 0.9626\n",
      "epoch: 183 / 700, training rmse: 0.3323, training r2: 0.9628\n",
      "epoch: 184 / 700, training rmse: 0.3319, training r2: 0.9629\n",
      "epoch: 185 / 700, training rmse: 0.3316, training r2: 0.963\n",
      "epoch: 186 / 700, training rmse: 0.3309, training r2: 0.9632\n",
      "epoch: 187 / 700, training rmse: 0.3297, training r2: 0.9634\n",
      "epoch: 188 / 700, training rmse: 0.3299, training r2: 0.9634\n",
      "epoch: 189 / 700, training rmse: 0.3288, training r2: 0.9636\n",
      "epoch: 190 / 700, training rmse: 0.3286, training r2: 0.9637\n",
      "epoch: 191 / 700, training rmse: 0.328, training r2: 0.9638\n",
      "epoch: 192 / 700, training rmse: 0.3274, training r2: 0.9639\n",
      "epoch: 193 / 700, training rmse: 0.3264, training r2: 0.9641\n",
      "epoch: 194 / 700, training rmse: 0.3262, training r2: 0.9642\n",
      "epoch: 195 / 700, training rmse: 0.3253, training r2: 0.9644\n",
      "epoch: 196 / 700, training rmse: 0.325, training r2: 0.9645\n",
      "epoch: 197 / 700, training rmse: 0.325, training r2: 0.9645\n",
      "epoch: 198 / 700, training rmse: 0.3241, training r2: 0.9647\n",
      "epoch: 199 / 700, training rmse: 0.3231, training r2: 0.9649\n",
      "epoch: 200 / 700, training rmse: 0.3222, training r2: 0.9651\n",
      "epoch: 201 / 700, training rmse: 0.322, training r2: 0.9651\n",
      "epoch: 202 / 700, training rmse: 0.322, training r2: 0.9651\n",
      "epoch: 203 / 700, training rmse: 0.321, training r2: 0.9653\n",
      "epoch: 204 / 700, training rmse: 0.321, training r2: 0.9653\n",
      "epoch: 205 / 700, training rmse: 0.3205, training r2: 0.9654\n",
      "epoch: 206 / 700, training rmse: 0.3199, training r2: 0.9656\n",
      "epoch: 207 / 700, training rmse: 0.3192, training r2: 0.9657\n",
      "epoch: 208 / 700, training rmse: 0.3185, training r2: 0.9659\n",
      "epoch: 209 / 700, training rmse: 0.3182, training r2: 0.9659\n",
      "epoch: 210 / 700, training rmse: 0.3173, training r2: 0.9661\n",
      "epoch: 211 / 700, training rmse: 0.3167, training r2: 0.9663\n",
      "epoch: 212 / 700, training rmse: 0.3164, training r2: 0.9663\n",
      "epoch: 213 / 700, training rmse: 0.3161, training r2: 0.9664\n",
      "epoch: 214 / 700, training rmse: 0.3153, training r2: 0.9665\n",
      "epoch: 215 / 700, training rmse: 0.315, training r2: 0.9666\n",
      "epoch: 216 / 700, training rmse: 0.3144, training r2: 0.9667\n",
      "epoch: 217 / 700, training rmse: 0.3141, training r2: 0.9668\n",
      "epoch: 218 / 700, training rmse: 0.3132, training r2: 0.967\n",
      "epoch: 219 / 700, training rmse: 0.3127, training r2: 0.9671\n",
      "epoch: 220 / 700, training rmse: 0.3127, training r2: 0.9671\n",
      "epoch: 221 / 700, training rmse: 0.3121, training r2: 0.9672\n",
      "epoch: 222 / 700, training rmse: 0.3114, training r2: 0.9674\n",
      "epoch: 223 / 700, training rmse: 0.311, training r2: 0.9674\n",
      "epoch: 224 / 700, training rmse: 0.3104, training r2: 0.9676\n",
      "epoch: 225 / 700, training rmse: 0.3106, training r2: 0.9675\n",
      "epoch: 226 / 700, training rmse: 0.3097, training r2: 0.9677\n",
      "epoch: 227 / 700, training rmse: 0.3096, training r2: 0.9677\n",
      "epoch: 228 / 700, training rmse: 0.309, training r2: 0.9679\n",
      "epoch: 229 / 700, training rmse: 0.3086, training r2: 0.968\n",
      "epoch: 230 / 700, training rmse: 0.3082, training r2: 0.968\n",
      "epoch: 231 / 700, training rmse: 0.3076, training r2: 0.9681\n",
      "epoch: 232 / 700, training rmse: 0.307, training r2: 0.9683\n",
      "epoch: 233 / 700, training rmse: 0.3066, training r2: 0.9684\n",
      "epoch: 234 / 700, training rmse: 0.3061, training r2: 0.9685\n",
      "epoch: 235 / 700, training rmse: 0.306, training r2: 0.9685\n",
      "epoch: 236 / 700, training rmse: 0.3052, training r2: 0.9686\n",
      "epoch: 237 / 700, training rmse: 0.3052, training r2: 0.9687\n",
      "epoch: 238 / 700, training rmse: 0.3045, training r2: 0.9688\n",
      "epoch: 239 / 700, training rmse: 0.3043, training r2: 0.9688\n",
      "epoch: 240 / 700, training rmse: 0.3035, training r2: 0.969\n",
      "epoch: 241 / 700, training rmse: 0.3035, training r2: 0.969\n",
      "epoch: 242 / 700, training rmse: 0.3027, training r2: 0.9692\n",
      "epoch: 243 / 700, training rmse: 0.3025, training r2: 0.9692\n",
      "epoch: 244 / 700, training rmse: 0.3022, training r2: 0.9693\n",
      "epoch: 245 / 700, training rmse: 0.3018, training r2: 0.9693\n",
      "epoch: 246 / 700, training rmse: 0.3014, training r2: 0.9694\n",
      "epoch: 247 / 700, training rmse: 0.3005, training r2: 0.9696\n",
      "epoch: 248 / 700, training rmse: 0.3007, training r2: 0.9696\n",
      "epoch: 249 / 700, training rmse: 0.3004, training r2: 0.9696\n",
      "epoch: 250 / 700, training rmse: 0.2997, training r2: 0.9698\n",
      "epoch: 251 / 700, training rmse: 0.2994, training r2: 0.9698\n",
      "epoch: 252 / 700, training rmse: 0.2992, training r2: 0.9699\n",
      "epoch: 253 / 700, training rmse: 0.2984, training r2: 0.97\n",
      "epoch: 254 / 700, training rmse: 0.2978, training r2: 0.9702\n",
      "epoch: 255 / 700, training rmse: 0.2977, training r2: 0.9702\n",
      "epoch: 256 / 700, training rmse: 0.2978, training r2: 0.9702\n",
      "epoch: 257 / 700, training rmse: 0.2971, training r2: 0.9703\n",
      "epoch: 258 / 700, training rmse: 0.2967, training r2: 0.9704\n",
      "epoch: 259 / 700, training rmse: 0.2961, training r2: 0.9705\n",
      "epoch: 260 / 700, training rmse: 0.2958, training r2: 0.9706\n",
      "epoch: 261 / 700, training rmse: 0.2957, training r2: 0.9706\n",
      "epoch: 262 / 700, training rmse: 0.2953, training r2: 0.9707\n",
      "epoch: 263 / 700, training rmse: 0.2946, training r2: 0.9708\n",
      "epoch: 264 / 700, training rmse: 0.294, training r2: 0.9709\n",
      "epoch: 265 / 700, training rmse: 0.294, training r2: 0.9709\n",
      "epoch: 266 / 700, training rmse: 0.2935, training r2: 0.971\n",
      "epoch: 267 / 700, training rmse: 0.2932, training r2: 0.9711\n",
      "epoch: 268 / 700, training rmse: 0.2927, training r2: 0.9712\n",
      "epoch: 269 / 700, training rmse: 0.2923, training r2: 0.9712\n",
      "epoch: 270 / 700, training rmse: 0.2918, training r2: 0.9713\n",
      "epoch: 271 / 700, training rmse: 0.2917, training r2: 0.9714\n",
      "epoch: 272 / 700, training rmse: 0.2915, training r2: 0.9714\n",
      "epoch: 273 / 700, training rmse: 0.2909, training r2: 0.9715\n",
      "epoch: 274 / 700, training rmse: 0.2904, training r2: 0.9716\n",
      "epoch: 275 / 700, training rmse: 0.2902, training r2: 0.9717\n",
      "epoch: 276 / 700, training rmse: 0.2898, training r2: 0.9717\n",
      "epoch: 277 / 700, training rmse: 0.2892, training r2: 0.9718\n",
      "epoch: 278 / 700, training rmse: 0.289, training r2: 0.9719\n",
      "epoch: 279 / 700, training rmse: 0.2887, training r2: 0.972\n",
      "epoch: 280 / 700, training rmse: 0.2884, training r2: 0.972\n",
      "epoch: 281 / 700, training rmse: 0.2882, training r2: 0.9721\n",
      "epoch: 282 / 700, training rmse: 0.2878, training r2: 0.9721\n",
      "epoch: 283 / 700, training rmse: 0.2873, training r2: 0.9722\n",
      "epoch: 284 / 700, training rmse: 0.2876, training r2: 0.9722\n",
      "epoch: 285 / 700, training rmse: 0.2867, training r2: 0.9723\n",
      "epoch: 286 / 700, training rmse: 0.2865, training r2: 0.9724\n",
      "epoch: 287 / 700, training rmse: 0.2861, training r2: 0.9724\n",
      "epoch: 288 / 700, training rmse: 0.2856, training r2: 0.9725\n",
      "epoch: 289 / 700, training rmse: 0.2855, training r2: 0.9726\n",
      "epoch: 290 / 700, training rmse: 0.2853, training r2: 0.9726\n",
      "epoch: 291 / 700, training rmse: 0.2846, training r2: 0.9727\n",
      "epoch: 292 / 700, training rmse: 0.2844, training r2: 0.9728\n",
      "epoch: 293 / 700, training rmse: 0.2842, training r2: 0.9728\n",
      "epoch: 294 / 700, training rmse: 0.2843, training r2: 0.9728\n",
      "epoch: 295 / 700, training rmse: 0.2835, training r2: 0.9729\n",
      "epoch: 296 / 700, training rmse: 0.2831, training r2: 0.973\n",
      "epoch: 297 / 700, training rmse: 0.283, training r2: 0.973\n",
      "epoch: 298 / 700, training rmse: 0.2826, training r2: 0.9731\n",
      "epoch: 299 / 700, training rmse: 0.2825, training r2: 0.9731\n",
      "epoch: 300 / 700, training rmse: 0.2822, training r2: 0.9732\n",
      "epoch: 301 / 700, training rmse: 0.2822, training r2: 0.9732\n",
      "epoch: 302 / 700, training rmse: 0.2817, training r2: 0.9733\n",
      "epoch: 303 / 700, training rmse: 0.2813, training r2: 0.9734\n",
      "epoch: 304 / 700, training rmse: 0.2813, training r2: 0.9734\n",
      "epoch: 305 / 700, training rmse: 0.2808, training r2: 0.9735\n",
      "epoch: 306 / 700, training rmse: 0.2809, training r2: 0.9735\n",
      "epoch: 307 / 700, training rmse: 0.2801, training r2: 0.9736\n",
      "epoch: 308 / 700, training rmse: 0.28, training r2: 0.9736\n",
      "epoch: 309 / 700, training rmse: 0.2796, training r2: 0.9737\n",
      "epoch: 310 / 700, training rmse: 0.2793, training r2: 0.9738\n",
      "epoch: 311 / 700, training rmse: 0.2788, training r2: 0.9738\n",
      "epoch: 312 / 700, training rmse: 0.2786, training r2: 0.9739\n",
      "epoch: 313 / 700, training rmse: 0.2783, training r2: 0.9739\n",
      "epoch: 314 / 700, training rmse: 0.2779, training r2: 0.974\n",
      "epoch: 315 / 700, training rmse: 0.2775, training r2: 0.9741\n",
      "epoch: 316 / 700, training rmse: 0.2773, training r2: 0.9741\n",
      "epoch: 317 / 700, training rmse: 0.277, training r2: 0.9742\n",
      "epoch: 318 / 700, training rmse: 0.2771, training r2: 0.9742\n",
      "epoch: 319 / 700, training rmse: 0.2761, training r2: 0.9743\n",
      "epoch: 320 / 700, training rmse: 0.2761, training r2: 0.9743\n",
      "epoch: 321 / 700, training rmse: 0.2756, training r2: 0.9744\n",
      "epoch: 322 / 700, training rmse: 0.2758, training r2: 0.9744\n",
      "epoch: 323 / 700, training rmse: 0.2754, training r2: 0.9745\n",
      "epoch: 324 / 700, training rmse: 0.2751, training r2: 0.9745\n",
      "epoch: 325 / 700, training rmse: 0.2746, training r2: 0.9746\n",
      "epoch: 326 / 700, training rmse: 0.2745, training r2: 0.9746\n",
      "epoch: 327 / 700, training rmse: 0.2744, training r2: 0.9747\n",
      "epoch: 328 / 700, training rmse: 0.274, training r2: 0.9747\n",
      "epoch: 329 / 700, training rmse: 0.2741, training r2: 0.9747\n",
      "epoch: 330 / 700, training rmse: 0.2735, training r2: 0.9748\n",
      "epoch: 331 / 700, training rmse: 0.2733, training r2: 0.9749\n",
      "epoch: 332 / 700, training rmse: 0.2731, training r2: 0.9749\n",
      "epoch: 333 / 700, training rmse: 0.2728, training r2: 0.975\n",
      "epoch: 334 / 700, training rmse: 0.2726, training r2: 0.975\n",
      "epoch: 335 / 700, training rmse: 0.2722, training r2: 0.9751\n",
      "epoch: 336 / 700, training rmse: 0.2718, training r2: 0.9751\n",
      "epoch: 337 / 700, training rmse: 0.2714, training r2: 0.9752\n",
      "epoch: 338 / 700, training rmse: 0.2714, training r2: 0.9752\n",
      "epoch: 339 / 700, training rmse: 0.2711, training r2: 0.9753\n",
      "epoch: 340 / 700, training rmse: 0.2712, training r2: 0.9752\n",
      "epoch: 341 / 700, training rmse: 0.2707, training r2: 0.9753\n",
      "epoch: 342 / 700, training rmse: 0.2703, training r2: 0.9754\n",
      "epoch: 343 / 700, training rmse: 0.2703, training r2: 0.9754\n",
      "epoch: 344 / 700, training rmse: 0.27, training r2: 0.9755\n",
      "epoch: 345 / 700, training rmse: 0.27, training r2: 0.9755\n",
      "epoch: 346 / 700, training rmse: 0.2694, training r2: 0.9756\n",
      "epoch: 347 / 700, training rmse: 0.2687, training r2: 0.9757\n",
      "epoch: 348 / 700, training rmse: 0.2694, training r2: 0.9756\n",
      "epoch: 349 / 700, training rmse: 0.2685, training r2: 0.9757\n",
      "epoch: 350 / 700, training rmse: 0.2686, training r2: 0.9757\n",
      "epoch: 351 / 700, training rmse: 0.268, training r2: 0.9758\n",
      "epoch: 352 / 700, training rmse: 0.2676, training r2: 0.9759\n",
      "epoch: 353 / 700, training rmse: 0.2679, training r2: 0.9759\n",
      "epoch: 354 / 700, training rmse: 0.2674, training r2: 0.9759\n",
      "epoch: 355 / 700, training rmse: 0.2671, training r2: 0.976\n",
      "epoch: 356 / 700, training rmse: 0.2668, training r2: 0.976\n",
      "epoch: 357 / 700, training rmse: 0.2667, training r2: 0.9761\n",
      "epoch: 358 / 700, training rmse: 0.2666, training r2: 0.9761\n",
      "epoch: 359 / 700, training rmse: 0.2668, training r2: 0.976\n",
      "epoch: 360 / 700, training rmse: 0.2661, training r2: 0.9762\n",
      "epoch: 361 / 700, training rmse: 0.2658, training r2: 0.9762\n",
      "epoch: 362 / 700, training rmse: 0.265, training r2: 0.9764\n",
      "epoch: 363 / 700, training rmse: 0.2649, training r2: 0.9764\n",
      "epoch: 364 / 700, training rmse: 0.2651, training r2: 0.9763\n",
      "epoch: 365 / 700, training rmse: 0.2645, training r2: 0.9765\n",
      "epoch: 366 / 700, training rmse: 0.2643, training r2: 0.9765\n",
      "epoch: 367 / 700, training rmse: 0.2643, training r2: 0.9765\n",
      "epoch: 368 / 700, training rmse: 0.264, training r2: 0.9765\n",
      "epoch: 369 / 700, training rmse: 0.264, training r2: 0.9765\n",
      "epoch: 370 / 700, training rmse: 0.2634, training r2: 0.9766\n",
      "epoch: 371 / 700, training rmse: 0.2634, training r2: 0.9766\n",
      "epoch: 372 / 700, training rmse: 0.2632, training r2: 0.9767\n",
      "epoch: 373 / 700, training rmse: 0.2627, training r2: 0.9768\n",
      "epoch: 374 / 700, training rmse: 0.263, training r2: 0.9767\n",
      "epoch: 375 / 700, training rmse: 0.2624, training r2: 0.9768\n",
      "epoch: 376 / 700, training rmse: 0.2623, training r2: 0.9768\n",
      "epoch: 377 / 700, training rmse: 0.2621, training r2: 0.9769\n",
      "epoch: 378 / 700, training rmse: 0.2617, training r2: 0.977\n",
      "epoch: 379 / 700, training rmse: 0.2616, training r2: 0.977\n",
      "epoch: 380 / 700, training rmse: 0.2612, training r2: 0.977\n",
      "epoch: 381 / 700, training rmse: 0.2611, training r2: 0.9771\n",
      "epoch: 382 / 700, training rmse: 0.2606, training r2: 0.9771\n",
      "epoch: 383 / 700, training rmse: 0.2606, training r2: 0.9771\n",
      "epoch: 384 / 700, training rmse: 0.2601, training r2: 0.9772\n",
      "epoch: 385 / 700, training rmse: 0.2603, training r2: 0.9772\n",
      "epoch: 386 / 700, training rmse: 0.2596, training r2: 0.9773\n",
      "epoch: 387 / 700, training rmse: 0.2597, training r2: 0.9773\n",
      "epoch: 388 / 700, training rmse: 0.2595, training r2: 0.9773\n",
      "epoch: 389 / 700, training rmse: 0.2593, training r2: 0.9774\n",
      "epoch: 390 / 700, training rmse: 0.2591, training r2: 0.9774\n",
      "epoch: 391 / 700, training rmse: 0.259, training r2: 0.9774\n",
      "epoch: 392 / 700, training rmse: 0.2586, training r2: 0.9775\n",
      "epoch: 393 / 700, training rmse: 0.2582, training r2: 0.9776\n",
      "epoch: 394 / 700, training rmse: 0.2584, training r2: 0.9775\n",
      "epoch: 395 / 700, training rmse: 0.2586, training r2: 0.9775\n",
      "epoch: 396 / 700, training rmse: 0.258, training r2: 0.9776\n",
      "epoch: 397 / 700, training rmse: 0.2579, training r2: 0.9776\n",
      "epoch: 398 / 700, training rmse: 0.2575, training r2: 0.9777\n",
      "epoch: 399 / 700, training rmse: 0.2574, training r2: 0.9777\n",
      "epoch: 400 / 700, training rmse: 0.2572, training r2: 0.9777\n",
      "epoch: 401 / 700, training rmse: 0.2572, training r2: 0.9777\n",
      "epoch: 402 / 700, training rmse: 0.2569, training r2: 0.9778\n",
      "epoch: 403 / 700, training rmse: 0.2572, training r2: 0.9777\n",
      "epoch: 404 / 700, training rmse: 0.2571, training r2: 0.9778\n",
      "epoch: 405 / 700, training rmse: 0.2566, training r2: 0.9778\n",
      "epoch: 406 / 700, training rmse: 0.2564, training r2: 0.9779\n",
      "epoch: 407 / 700, training rmse: 0.2563, training r2: 0.9779\n",
      "epoch: 408 / 700, training rmse: 0.2558, training r2: 0.978\n",
      "epoch: 409 / 700, training rmse: 0.2559, training r2: 0.978\n",
      "epoch: 410 / 700, training rmse: 0.2556, training r2: 0.978\n",
      "epoch: 411 / 700, training rmse: 0.2551, training r2: 0.9781\n",
      "epoch: 412 / 700, training rmse: 0.255, training r2: 0.9781\n",
      "epoch: 413 / 700, training rmse: 0.2544, training r2: 0.9782\n",
      "epoch: 414 / 700, training rmse: 0.2545, training r2: 0.9782\n",
      "epoch: 415 / 700, training rmse: 0.2543, training r2: 0.9782\n",
      "epoch: 416 / 700, training rmse: 0.2541, training r2: 0.9783\n",
      "epoch: 417 / 700, training rmse: 0.2538, training r2: 0.9783\n",
      "epoch: 418 / 700, training rmse: 0.2536, training r2: 0.9783\n",
      "epoch: 419 / 700, training rmse: 0.2537, training r2: 0.9783\n",
      "epoch: 420 / 700, training rmse: 0.2532, training r2: 0.9784\n",
      "epoch: 421 / 700, training rmse: 0.2532, training r2: 0.9784\n",
      "epoch: 422 / 700, training rmse: 0.2527, training r2: 0.9785\n",
      "epoch: 423 / 700, training rmse: 0.2527, training r2: 0.9785\n",
      "epoch: 424 / 700, training rmse: 0.2527, training r2: 0.9785\n",
      "epoch: 425 / 700, training rmse: 0.2529, training r2: 0.9785\n",
      "epoch: 426 / 700, training rmse: 0.2526, training r2: 0.9785\n",
      "epoch: 427 / 700, training rmse: 0.2517, training r2: 0.9787\n",
      "epoch: 428 / 700, training rmse: 0.252, training r2: 0.9786\n",
      "epoch: 429 / 700, training rmse: 0.2515, training r2: 0.9787\n",
      "epoch: 430 / 700, training rmse: 0.2516, training r2: 0.9787\n",
      "epoch: 431 / 700, training rmse: 0.2514, training r2: 0.9787\n",
      "epoch: 432 / 700, training rmse: 0.2511, training r2: 0.9788\n",
      "epoch: 433 / 700, training rmse: 0.2508, training r2: 0.9788\n",
      "epoch: 434 / 700, training rmse: 0.2509, training r2: 0.9788\n",
      "epoch: 435 / 700, training rmse: 0.2504, training r2: 0.9789\n",
      "epoch: 436 / 700, training rmse: 0.2506, training r2: 0.9789\n",
      "epoch: 437 / 700, training rmse: 0.25, training r2: 0.979\n",
      "epoch: 438 / 700, training rmse: 0.2501, training r2: 0.9789\n",
      "epoch: 439 / 700, training rmse: 0.2502, training r2: 0.9789\n",
      "epoch: 440 / 700, training rmse: 0.2494, training r2: 0.9791\n",
      "epoch: 441 / 700, training rmse: 0.2494, training r2: 0.9791\n",
      "epoch: 442 / 700, training rmse: 0.2492, training r2: 0.9791\n",
      "epoch: 443 / 700, training rmse: 0.2496, training r2: 0.979\n",
      "epoch: 444 / 700, training rmse: 0.2487, training r2: 0.9792\n",
      "epoch: 445 / 700, training rmse: 0.2486, training r2: 0.9792\n",
      "epoch: 446 / 700, training rmse: 0.2488, training r2: 0.9792\n",
      "epoch: 447 / 700, training rmse: 0.2486, training r2: 0.9792\n",
      "epoch: 448 / 700, training rmse: 0.2482, training r2: 0.9793\n",
      "epoch: 449 / 700, training rmse: 0.2484, training r2: 0.9792\n",
      "epoch: 450 / 700, training rmse: 0.248, training r2: 0.9793\n",
      "epoch: 451 / 700, training rmse: 0.2482, training r2: 0.9793\n",
      "epoch: 452 / 700, training rmse: 0.2476, training r2: 0.9794\n",
      "epoch: 453 / 700, training rmse: 0.2479, training r2: 0.9793\n",
      "epoch: 454 / 700, training rmse: 0.2477, training r2: 0.9793\n",
      "epoch: 455 / 700, training rmse: 0.2473, training r2: 0.9794\n",
      "epoch: 456 / 700, training rmse: 0.2474, training r2: 0.9794\n",
      "epoch: 457 / 700, training rmse: 0.2467, training r2: 0.9795\n",
      "epoch: 458 / 700, training rmse: 0.2471, training r2: 0.9794\n",
      "epoch: 459 / 700, training rmse: 0.2466, training r2: 0.9795\n",
      "epoch: 460 / 700, training rmse: 0.2468, training r2: 0.9795\n",
      "epoch: 461 / 700, training rmse: 0.2465, training r2: 0.9796\n",
      "epoch: 462 / 700, training rmse: 0.2458, training r2: 0.9797\n",
      "epoch: 463 / 700, training rmse: 0.2463, training r2: 0.9796\n",
      "epoch: 464 / 700, training rmse: 0.246, training r2: 0.9796\n",
      "epoch: 465 / 700, training rmse: 0.2459, training r2: 0.9797\n",
      "epoch: 466 / 700, training rmse: 0.2456, training r2: 0.9797\n",
      "epoch: 467 / 700, training rmse: 0.2454, training r2: 0.9797\n",
      "epoch: 468 / 700, training rmse: 0.2449, training r2: 0.9798\n",
      "epoch: 469 / 700, training rmse: 0.2451, training r2: 0.9798\n",
      "epoch: 470 / 700, training rmse: 0.2447, training r2: 0.9798\n",
      "epoch: 471 / 700, training rmse: 0.2448, training r2: 0.9798\n",
      "epoch: 472 / 700, training rmse: 0.2443, training r2: 0.9799\n",
      "epoch: 473 / 700, training rmse: 0.244, training r2: 0.98\n",
      "epoch: 474 / 700, training rmse: 0.2442, training r2: 0.9799\n",
      "epoch: 475 / 700, training rmse: 0.244, training r2: 0.98\n",
      "epoch: 476 / 700, training rmse: 0.2438, training r2: 0.98\n",
      "epoch: 477 / 700, training rmse: 0.2435, training r2: 0.98\n",
      "epoch: 478 / 700, training rmse: 0.2437, training r2: 0.98\n",
      "epoch: 479 / 700, training rmse: 0.2432, training r2: 0.9801\n",
      "epoch: 480 / 700, training rmse: 0.2438, training r2: 0.98\n",
      "epoch: 481 / 700, training rmse: 0.2428, training r2: 0.9802\n",
      "epoch: 482 / 700, training rmse: 0.2433, training r2: 0.9801\n",
      "epoch: 483 / 700, training rmse: 0.2428, training r2: 0.9802\n",
      "epoch: 484 / 700, training rmse: 0.2427, training r2: 0.9802\n",
      "epoch: 485 / 700, training rmse: 0.2428, training r2: 0.9802\n",
      "epoch: 486 / 700, training rmse: 0.2428, training r2: 0.9802\n",
      "epoch: 487 / 700, training rmse: 0.2422, training r2: 0.9803\n",
      "epoch: 488 / 700, training rmse: 0.2421, training r2: 0.9803\n",
      "epoch: 489 / 700, training rmse: 0.2419, training r2: 0.9803\n",
      "epoch: 490 / 700, training rmse: 0.2418, training r2: 0.9803\n",
      "epoch: 491 / 700, training rmse: 0.2416, training r2: 0.9803\n",
      "epoch: 492 / 700, training rmse: 0.2416, training r2: 0.9804\n",
      "epoch: 493 / 700, training rmse: 0.2414, training r2: 0.9804\n",
      "epoch: 494 / 700, training rmse: 0.2411, training r2: 0.9804\n",
      "epoch: 495 / 700, training rmse: 0.2413, training r2: 0.9804\n",
      "epoch: 496 / 700, training rmse: 0.241, training r2: 0.9805\n",
      "epoch: 497 / 700, training rmse: 0.2408, training r2: 0.9805\n",
      "epoch: 498 / 700, training rmse: 0.2404, training r2: 0.9805\n",
      "epoch: 499 / 700, training rmse: 0.2405, training r2: 0.9805\n",
      "epoch: 500 / 700, training rmse: 0.2403, training r2: 0.9806\n",
      "epoch: 501 / 700, training rmse: 0.2402, training r2: 0.9806\n",
      "epoch: 502 / 700, training rmse: 0.2402, training r2: 0.9806\n",
      "epoch: 503 / 700, training rmse: 0.2399, training r2: 0.9806\n",
      "epoch: 504 / 700, training rmse: 0.2397, training r2: 0.9807\n",
      "epoch: 505 / 700, training rmse: 0.2395, training r2: 0.9807\n",
      "epoch: 506 / 700, training rmse: 0.2392, training r2: 0.9807\n",
      "epoch: 507 / 700, training rmse: 0.2396, training r2: 0.9807\n",
      "epoch: 508 / 700, training rmse: 0.2397, training r2: 0.9807\n",
      "epoch: 509 / 700, training rmse: 0.2391, training r2: 0.9808\n",
      "epoch: 510 / 700, training rmse: 0.2389, training r2: 0.9808\n",
      "epoch: 511 / 700, training rmse: 0.2387, training r2: 0.9808\n",
      "epoch: 512 / 700, training rmse: 0.2387, training r2: 0.9808\n",
      "epoch: 513 / 700, training rmse: 0.2387, training r2: 0.9808\n",
      "epoch: 514 / 700, training rmse: 0.2385, training r2: 0.9809\n",
      "epoch: 515 / 700, training rmse: 0.2385, training r2: 0.9809\n",
      "epoch: 516 / 700, training rmse: 0.2383, training r2: 0.9809\n",
      "epoch: 517 / 700, training rmse: 0.2383, training r2: 0.9809\n",
      "epoch: 518 / 700, training rmse: 0.2383, training r2: 0.9809\n",
      "epoch: 519 / 700, training rmse: 0.2379, training r2: 0.981\n",
      "epoch: 520 / 700, training rmse: 0.2375, training r2: 0.981\n",
      "epoch: 521 / 700, training rmse: 0.2377, training r2: 0.981\n",
      "epoch: 522 / 700, training rmse: 0.2374, training r2: 0.981\n",
      "epoch: 523 / 700, training rmse: 0.2377, training r2: 0.981\n",
      "epoch: 524 / 700, training rmse: 0.2376, training r2: 0.981\n",
      "epoch: 525 / 700, training rmse: 0.2373, training r2: 0.981\n",
      "epoch: 526 / 700, training rmse: 0.2374, training r2: 0.981\n",
      "epoch: 527 / 700, training rmse: 0.2368, training r2: 0.9811\n",
      "epoch: 528 / 700, training rmse: 0.2368, training r2: 0.9811\n",
      "epoch: 529 / 700, training rmse: 0.2365, training r2: 0.9812\n",
      "epoch: 530 / 700, training rmse: 0.2363, training r2: 0.9812\n",
      "epoch: 531 / 700, training rmse: 0.2363, training r2: 0.9812\n",
      "epoch: 532 / 700, training rmse: 0.2366, training r2: 0.9812\n",
      "epoch: 533 / 700, training rmse: 0.2362, training r2: 0.9812\n",
      "epoch: 534 / 700, training rmse: 0.2359, training r2: 0.9813\n",
      "epoch: 535 / 700, training rmse: 0.2355, training r2: 0.9813\n",
      "epoch: 536 / 700, training rmse: 0.2358, training r2: 0.9813\n",
      "epoch: 537 / 700, training rmse: 0.2357, training r2: 0.9813\n",
      "epoch: 538 / 700, training rmse: 0.2353, training r2: 0.9814\n",
      "epoch: 539 / 700, training rmse: 0.2352, training r2: 0.9814\n",
      "epoch: 540 / 700, training rmse: 0.2354, training r2: 0.9814\n",
      "epoch: 541 / 700, training rmse: 0.2352, training r2: 0.9814\n",
      "epoch: 542 / 700, training rmse: 0.2353, training r2: 0.9814\n",
      "epoch: 543 / 700, training rmse: 0.2351, training r2: 0.9814\n",
      "epoch: 544 / 700, training rmse: 0.2351, training r2: 0.9814\n",
      "epoch: 545 / 700, training rmse: 0.235, training r2: 0.9814\n",
      "epoch: 546 / 700, training rmse: 0.2349, training r2: 0.9814\n",
      "epoch: 547 / 700, training rmse: 0.2347, training r2: 0.9815\n",
      "epoch: 548 / 700, training rmse: 0.2344, training r2: 0.9815\n",
      "epoch: 549 / 700, training rmse: 0.2341, training r2: 0.9816\n",
      "epoch: 550 / 700, training rmse: 0.2343, training r2: 0.9815\n",
      "epoch: 551 / 700, training rmse: 0.2338, training r2: 0.9816\n",
      "epoch: 552 / 700, training rmse: 0.2339, training r2: 0.9816\n",
      "epoch: 553 / 700, training rmse: 0.2335, training r2: 0.9816\n",
      "epoch: 554 / 700, training rmse: 0.2335, training r2: 0.9817\n",
      "epoch: 555 / 700, training rmse: 0.2336, training r2: 0.9816\n",
      "epoch: 556 / 700, training rmse: 0.2334, training r2: 0.9817\n",
      "epoch: 557 / 700, training rmse: 0.2331, training r2: 0.9817\n",
      "epoch: 558 / 700, training rmse: 0.2333, training r2: 0.9817\n",
      "epoch: 559 / 700, training rmse: 0.2333, training r2: 0.9817\n",
      "epoch: 560 / 700, training rmse: 0.2327, training r2: 0.9818\n",
      "epoch: 561 / 700, training rmse: 0.2327, training r2: 0.9818\n",
      "epoch: 562 / 700, training rmse: 0.2328, training r2: 0.9818\n",
      "epoch: 563 / 700, training rmse: 0.2324, training r2: 0.9818\n",
      "epoch: 564 / 700, training rmse: 0.2322, training r2: 0.9818\n",
      "epoch: 565 / 700, training rmse: 0.232, training r2: 0.9819\n",
      "epoch: 566 / 700, training rmse: 0.2322, training r2: 0.9818\n",
      "epoch: 567 / 700, training rmse: 0.2318, training r2: 0.9819\n",
      "epoch: 568 / 700, training rmse: 0.232, training r2: 0.9819\n",
      "epoch: 569 / 700, training rmse: 0.2318, training r2: 0.9819\n",
      "epoch: 570 / 700, training rmse: 0.2318, training r2: 0.9819\n",
      "epoch: 571 / 700, training rmse: 0.2317, training r2: 0.9819\n",
      "epoch: 572 / 700, training rmse: 0.2311, training r2: 0.982\n",
      "epoch: 573 / 700, training rmse: 0.2309, training r2: 0.9821\n",
      "epoch: 574 / 700, training rmse: 0.2311, training r2: 0.982\n",
      "epoch: 575 / 700, training rmse: 0.2316, training r2: 0.9819\n",
      "epoch: 576 / 700, training rmse: 0.2309, training r2: 0.9821\n",
      "epoch: 577 / 700, training rmse: 0.2307, training r2: 0.9821\n",
      "epoch: 578 / 700, training rmse: 0.2307, training r2: 0.9821\n",
      "epoch: 579 / 700, training rmse: 0.2304, training r2: 0.9821\n",
      "epoch: 580 / 700, training rmse: 0.2306, training r2: 0.9821\n",
      "epoch: 581 / 700, training rmse: 0.2305, training r2: 0.9821\n",
      "epoch: 582 / 700, training rmse: 0.2303, training r2: 0.9821\n",
      "epoch: 583 / 700, training rmse: 0.2301, training r2: 0.9822\n",
      "epoch: 584 / 700, training rmse: 0.2299, training r2: 0.9822\n",
      "epoch: 585 / 700, training rmse: 0.23, training r2: 0.9822\n",
      "epoch: 586 / 700, training rmse: 0.2299, training r2: 0.9822\n",
      "epoch: 587 / 700, training rmse: 0.2294, training r2: 0.9823\n",
      "epoch: 588 / 700, training rmse: 0.2296, training r2: 0.9823\n",
      "epoch: 589 / 700, training rmse: 0.2292, training r2: 0.9823\n",
      "epoch: 590 / 700, training rmse: 0.2295, training r2: 0.9823\n",
      "epoch: 591 / 700, training rmse: 0.2296, training r2: 0.9823\n",
      "epoch: 592 / 700, training rmse: 0.2296, training r2: 0.9823\n",
      "epoch: 593 / 700, training rmse: 0.229, training r2: 0.9824\n",
      "epoch: 594 / 700, training rmse: 0.2293, training r2: 0.9823\n",
      "epoch: 595 / 700, training rmse: 0.2292, training r2: 0.9823\n",
      "epoch: 596 / 700, training rmse: 0.2287, training r2: 0.9824\n",
      "epoch: 597 / 700, training rmse: 0.2286, training r2: 0.9824\n",
      "epoch: 598 / 700, training rmse: 0.2283, training r2: 0.9825\n",
      "epoch: 599 / 700, training rmse: 0.2282, training r2: 0.9825\n",
      "epoch: 600 / 700, training rmse: 0.2285, training r2: 0.9824\n",
      "epoch: 601 / 700, training rmse: 0.2288, training r2: 0.9824\n",
      "epoch: 602 / 700, training rmse: 0.228, training r2: 0.9825\n",
      "epoch: 603 / 700, training rmse: 0.2286, training r2: 0.9824\n",
      "epoch: 604 / 700, training rmse: 0.2283, training r2: 0.9825\n",
      "epoch: 605 / 700, training rmse: 0.2282, training r2: 0.9825\n",
      "epoch: 606 / 700, training rmse: 0.2276, training r2: 0.9826\n",
      "epoch: 607 / 700, training rmse: 0.2279, training r2: 0.9825\n",
      "epoch: 608 / 700, training rmse: 0.2278, training r2: 0.9825\n",
      "epoch: 609 / 700, training rmse: 0.2277, training r2: 0.9825\n",
      "epoch: 610 / 700, training rmse: 0.2277, training r2: 0.9826\n",
      "epoch: 611 / 700, training rmse: 0.2277, training r2: 0.9825\n",
      "epoch: 612 / 700, training rmse: 0.2272, training r2: 0.9826\n",
      "epoch: 613 / 700, training rmse: 0.227, training r2: 0.9827\n",
      "epoch: 614 / 700, training rmse: 0.2269, training r2: 0.9827\n",
      "epoch: 615 / 700, training rmse: 0.2274, training r2: 0.9826\n",
      "epoch: 616 / 700, training rmse: 0.2272, training r2: 0.9826\n",
      "epoch: 617 / 700, training rmse: 0.2265, training r2: 0.9827\n",
      "epoch: 618 / 700, training rmse: 0.2265, training r2: 0.9827\n",
      "epoch: 619 / 700, training rmse: 0.2262, training r2: 0.9828\n",
      "epoch: 620 / 700, training rmse: 0.2268, training r2: 0.9827\n",
      "epoch: 621 / 700, training rmse: 0.2261, training r2: 0.9828\n",
      "epoch: 622 / 700, training rmse: 0.2265, training r2: 0.9827\n",
      "epoch: 623 / 700, training rmse: 0.2267, training r2: 0.9827\n",
      "epoch: 624 / 700, training rmse: 0.2266, training r2: 0.9827\n",
      "epoch: 625 / 700, training rmse: 0.2261, training r2: 0.9828\n",
      "epoch: 626 / 700, training rmse: 0.226, training r2: 0.9828\n",
      "epoch: 627 / 700, training rmse: 0.226, training r2: 0.9828\n",
      "epoch: 628 / 700, training rmse: 0.2257, training r2: 0.9828\n",
      "epoch: 629 / 700, training rmse: 0.2256, training r2: 0.9829\n",
      "epoch: 630 / 700, training rmse: 0.2255, training r2: 0.9829\n",
      "epoch: 631 / 700, training rmse: 0.2257, training r2: 0.9829\n",
      "epoch: 632 / 700, training rmse: 0.2254, training r2: 0.9829\n",
      "epoch: 633 / 700, training rmse: 0.2254, training r2: 0.9829\n",
      "epoch: 634 / 700, training rmse: 0.225, training r2: 0.983\n",
      "epoch: 635 / 700, training rmse: 0.2252, training r2: 0.9829\n",
      "epoch: 636 / 700, training rmse: 0.2248, training r2: 0.983\n",
      "epoch: 637 / 700, training rmse: 0.2248, training r2: 0.983\n",
      "epoch: 638 / 700, training rmse: 0.225, training r2: 0.983\n",
      "epoch: 639 / 700, training rmse: 0.2242, training r2: 0.9831\n",
      "epoch: 640 / 700, training rmse: 0.2251, training r2: 0.983\n",
      "epoch: 641 / 700, training rmse: 0.2248, training r2: 0.983\n",
      "epoch: 642 / 700, training rmse: 0.2241, training r2: 0.9831\n",
      "epoch: 643 / 700, training rmse: 0.2243, training r2: 0.9831\n",
      "epoch: 644 / 700, training rmse: 0.2243, training r2: 0.9831\n",
      "epoch: 645 / 700, training rmse: 0.2243, training r2: 0.9831\n",
      "epoch: 646 / 700, training rmse: 0.2241, training r2: 0.9831\n",
      "epoch: 647 / 700, training rmse: 0.2238, training r2: 0.9831\n",
      "epoch: 648 / 700, training rmse: 0.224, training r2: 0.9831\n",
      "epoch: 649 / 700, training rmse: 0.2242, training r2: 0.9831\n",
      "epoch: 650 / 700, training rmse: 0.2242, training r2: 0.9831\n",
      "epoch: 651 / 700, training rmse: 0.2239, training r2: 0.9831\n",
      "epoch: 652 / 700, training rmse: 0.224, training r2: 0.9831\n",
      "epoch: 653 / 700, training rmse: 0.2237, training r2: 0.9832\n",
      "epoch: 654 / 700, training rmse: 0.2239, training r2: 0.9831\n",
      "epoch: 655 / 700, training rmse: 0.2233, training r2: 0.9832\n",
      "epoch: 656 / 700, training rmse: 0.2234, training r2: 0.9832\n",
      "epoch: 657 / 700, training rmse: 0.2236, training r2: 0.9832\n",
      "epoch: 658 / 700, training rmse: 0.2234, training r2: 0.9832\n",
      "epoch: 659 / 700, training rmse: 0.2229, training r2: 0.9833\n",
      "epoch: 660 / 700, training rmse: 0.2233, training r2: 0.9832\n",
      "epoch: 661 / 700, training rmse: 0.2234, training r2: 0.9832\n",
      "epoch: 662 / 700, training rmse: 0.2231, training r2: 0.9832\n",
      "epoch: 663 / 700, training rmse: 0.2229, training r2: 0.9833\n",
      "epoch: 664 / 700, training rmse: 0.2228, training r2: 0.9833\n",
      "epoch: 665 / 700, training rmse: 0.2223, training r2: 0.9834\n",
      "epoch: 666 / 700, training rmse: 0.2228, training r2: 0.9833\n",
      "epoch: 667 / 700, training rmse: 0.2221, training r2: 0.9834\n",
      "epoch: 668 / 700, training rmse: 0.2224, training r2: 0.9834\n",
      "epoch: 669 / 700, training rmse: 0.2219, training r2: 0.9834\n",
      "epoch: 670 / 700, training rmse: 0.2218, training r2: 0.9834\n",
      "epoch: 671 / 700, training rmse: 0.2222, training r2: 0.9834\n",
      "epoch: 672 / 700, training rmse: 0.2219, training r2: 0.9834\n",
      "epoch: 673 / 700, training rmse: 0.2219, training r2: 0.9834\n",
      "epoch: 674 / 700, training rmse: 0.2219, training r2: 0.9834\n",
      "epoch: 675 / 700, training rmse: 0.2219, training r2: 0.9834\n",
      "epoch: 676 / 700, training rmse: 0.2216, training r2: 0.9835\n",
      "epoch: 677 / 700, training rmse: 0.2212, training r2: 0.9835\n",
      "epoch: 678 / 700, training rmse: 0.2214, training r2: 0.9835\n",
      "epoch: 679 / 700, training rmse: 0.2212, training r2: 0.9835\n",
      "epoch: 680 / 700, training rmse: 0.2213, training r2: 0.9835\n",
      "epoch: 681 / 700, training rmse: 0.2212, training r2: 0.9835\n",
      "epoch: 682 / 700, training rmse: 0.221, training r2: 0.9836\n",
      "epoch: 683 / 700, training rmse: 0.2213, training r2: 0.9835\n",
      "epoch: 684 / 700, training rmse: 0.2208, training r2: 0.9836\n",
      "epoch: 685 / 700, training rmse: 0.2208, training r2: 0.9836\n",
      "epoch: 686 / 700, training rmse: 0.221, training r2: 0.9836\n",
      "epoch: 687 / 700, training rmse: 0.2207, training r2: 0.9836\n",
      "epoch: 688 / 700, training rmse: 0.2207, training r2: 0.9836\n",
      "epoch: 689 / 700, training rmse: 0.2206, training r2: 0.9836\n",
      "epoch: 690 / 700, training rmse: 0.2208, training r2: 0.9836\n",
      "epoch: 691 / 700, training rmse: 0.2204, training r2: 0.9837\n",
      "epoch: 692 / 700, training rmse: 0.2207, training r2: 0.9836\n",
      "epoch: 693 / 700, training rmse: 0.221, training r2: 0.9836\n",
      "epoch: 694 / 700, training rmse: 0.2203, training r2: 0.9837\n",
      "epoch: 695 / 700, training rmse: 0.2203, training r2: 0.9837\n",
      "epoch: 696 / 700, training rmse: 0.2198, training r2: 0.9837\n",
      "epoch: 697 / 700, training rmse: 0.2197, training r2: 0.9838\n",
      "epoch: 698 / 700, training rmse: 0.2202, training r2: 0.9837\n",
      "epoch: 699 / 700, training rmse: 0.2194, training r2: 0.9838\n",
      "epoch: 700 / 700, training rmse: 0.2194, training r2: 0.9838\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor_grids = bird_gp_uncertainty.generate_grids([28, 112])\n",
    "outcome_grids = bird_gp_uncertainty.generate_grids([28, 28])\n",
    "\n",
    "birdgp = bird_gp_uncertainty.BIRD_GP(predictor_grids = predictor_grids,\n",
    "                                     outcome_grids = outcome_grids,\n",
    "                                     predictor_L = 50,\n",
    "                                     outcome_L = 50,\n",
    "                                     svgd_a_lambda = 0.01,\n",
    "                                     svgd_b_lambda = 0.01,\n",
    "                                     bf_predictor_steps = 10000,\n",
    "                                     bf_outcome_steps = 10000,\n",
    "                                     svgd_num_particles = 20,\n",
    "                                     svgd_epochs = 700\n",
    "                                     )\n",
    "birdgp.fit(train_predictors, train_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ba062-3690-47f5-bdde-ac183d32cbdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c2ba062-3690-47f5-bdde-ac183d32cbdf",
    "outputId": "1b59e853-a09b-49b7-978a-a85169d7b3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:05<00:00,  7.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_pred, train_coverage_rate = birdgp.predict_train(sample = True, size = 500, CI = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2452a5e-dc76-42c4-ab6b-4c06cad931a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2452a5e-dc76-42c4-ab6b-4c06cad931a5",
    "outputId": "11034a07-2f72-4e8e-c284-204795fe13c5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:33<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling testing images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:48<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred, test_coverage_rate = birdgp.predict_test(test_predictors, sample = True, size = 500, test_outcomes = test_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g0GREkwOsM1X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0GREkwOsM1X",
    "outputId": "15a85ac0-c8a9-4be4-989b-6716fe952c11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9540816326530612, 0.9948979591836735)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(train_coverage_rate, 0.025), np.quantile(train_coverage_rate, 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RtIISvb6sY2S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtIISvb6sY2S",
    "outputId": "bd45114e-3c80-4da6-a4d8-ebeeeebd0e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8762436224489797, 0.9961734693877551)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(test_coverage_rate, 0.025), np.quantile(test_coverage_rate, 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_XluGOVJ1S0o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XluGOVJ1S0o",
    "outputId": "8c8fcaf4-662b-4cd9-989e-0d3bcf2ec262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010767571577084521"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(train_coverage_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqQO-Zpr1W42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqQO-Zpr1W42",
    "outputId": "76fdf8cf-1224-4ac2-df3c-b9ff0dd76736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03181902173969297"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(test_coverage_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EgNMbEtzsdH9",
   "metadata": {
    "id": "EgNMbEtzsdH9"
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"train_coverage_rate.txt\", train_coverage_rate)\n",
    "np.savetxt(\"test_coverage_rate.txt\", test_coverage_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a387457-b97c-4564-994a-a2741c4ce4d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a387457-b97c-4564-994a-a2741c4ce4d5",
    "outputId": "cee7e10c-8ba5-431e-8914-e1a7beade22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9766530612244898, 0.9585943877551021)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_coverage_rate), np.mean(test_coverage_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58481216-2628-4783-b9b9-2b94ba695155",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58481216-2628-4783-b9b9-2b94ba695155",
    "outputId": "c1e88486-c316-4f3f-8149-47548b747571",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.016514566396214007, 0.02231107887794728)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((train_pred - train_outcomes)**2), np.mean((test_pred - test_outcomes)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721e259-2874-41fe-9ff2-6539bffa2f0c",
   "metadata": {
    "id": "0721e259-2874-41fe-9ff2-6539bffa2f0c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
