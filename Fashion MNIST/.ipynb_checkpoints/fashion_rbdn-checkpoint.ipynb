{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f",
   "metadata": {
    "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, predictors, labels):\n",
    "        self.labels = labels\n",
    "        self.predictors = predictors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.predictors[index, :]\n",
    "        y = self.labels[index, :]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "x2PZbM4dz4cQ",
   "metadata": {
    "id": "x2PZbM4dz4cQ"
   },
   "outputs": [],
   "source": [
    "class RBDN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 5, stride = 1, padding = 2)\n",
    "        \n",
    "        self.convB11 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB12 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB21 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB22 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB31 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB32 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.deconvB1 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconvB2 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconvB3 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB1 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB2 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB2 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB3 = nn.MaxUnpool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv7 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv8 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv9 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.unpoolL = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconvL = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # B11\n",
    "        xB11 = F.relu(self.convB11(x1))\n",
    "        xB11 = self.poolB1(xB11)\n",
    "\n",
    "        # B21\n",
    "        xB21 = F.relu(self.convB21(xB11))\n",
    "        xB21 = self.poolB2(xB21)\n",
    "\n",
    "        # B3\n",
    "        xB3 = F.relu(self.convB31(xB21))\n",
    "        xB3 = self.poolB3(xB3)\n",
    "        xB3 = F.relu(self.convB32(xB3))\n",
    "        xB3 = self.unpoolB3(xB3)\n",
    "        xB3 = F.relu(self.deconvB3(xB3))\n",
    "\n",
    "        # B22\n",
    "        xB22 = torch.cat((xB21, xB3), axis = 1)\n",
    "        xB22 = F.relu(self.convB22(xB22))\n",
    "        xB22 = self.unpoolB2(xB22)\n",
    "        xB22 = F.relu(self.deconvB2(xB22))\n",
    "\n",
    "        # B12\n",
    "        xB12 = torch.cat((xB11, xB22), axis = 1)\n",
    "        xB12 = F.relu(self.convB12(xB12))\n",
    "        xB12 = self.unpoolB1(xB12)\n",
    "        xB12 = F.relu(self.deconvB1(xB12))\n",
    "\n",
    "        # conv 2-9\n",
    "        x = torch.cat((x1, xB12), axis = 1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        x = self.unpoolL(x)\n",
    "        x = self.deconvL(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "507W2nRcQKWJ",
   "metadata": {
    "id": "507W2nRcQKWJ"
   },
   "outputs": [],
   "source": [
    "class RBDN(nn.Module):\n",
    "    def __init__(self, num_channels = 64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = num_channels, kernel_size = 5, stride = 1, padding = 2)\n",
    "        \n",
    "        self.convB11 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB12 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.deconvB1 = nn.ConvTranspose2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        self.poolB1 = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB1 = nn.MaxUnpool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = num_channels * 2, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv7 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv8 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv9 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.unpoolL = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconvL = nn.ConvTranspose2d(in_channels = num_channels, out_channels = 1, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x1, idx1 = self.pool1(x1)\n",
    "\n",
    "        # B1\n",
    "        xB11 = F.relu(self.convB11(x1))\n",
    "        xB11, idxB1 = self.poolB1(xB11)\n",
    "        xB12 = F.relu(self.convB12(xB11))\n",
    "        xB12 = self.unpoolB1(xB12, indices = idxB1)\n",
    "        xB12 = F.relu(self.deconvB1(xB12))\n",
    "\n",
    "        # conv 2-9\n",
    "        x = torch.cat((x1, xB12), axis = 1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        x = self.unpoolL(x, indices = idx1)\n",
    "        x = self.deconvL(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80fad42f-481e-4e7f-aa29-7441607064e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445313"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels = 64\n",
    "rbdn = RBDN(num_channels)\n",
    "sum([p.numel() for p in rbdn.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b",
   "metadata": {
    "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b"
   },
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"fashion-mnist_train.csv\", skiprows = 1, delimiter = \",\")\n",
    "test_data = np.loadtxt(\"fashion-mnist_test.csv\", skiprows = 1, delimiter = \",\")\n",
    "\n",
    "train_img = train_data[:, 1:]\n",
    "test_img = test_data[:, 1:]\n",
    "train_label = train_data[:, 0]\n",
    "test_label = test_data[:, 0]\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255\n",
    "\n",
    "train_idx_all = np.arange(60000)\n",
    "test_idx_all = np.arange(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6bf4d06b-7320-431c-ce34-dd050b5c084f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.03183671604201324 0.05997440799546761\n",
      "1 0.028112346753245348 0.03967142362843392\n",
      "2 0.03247798115966877 0.05614195362114102\n",
      "3 0.03405832968122399 0.045341083475639\n",
      "4 0.030918063012268338 0.04698811771253044\n",
      "5 0.026032466034815026 0.051097723735983584\n",
      "6 0.029460508808956634 0.04446909990919047\n",
      "7 0.025476917214574835 0.04611815398865871\n",
      "8 0.03630754846466739 0.056051359671980876\n",
      "9 0.029242342680338537 0.0463854644746687\n",
      "10 0.02743156440980799 0.04556926659342202\n",
      "11 0.028667399283391043 0.04355979551438229\n",
      "12 0.03042843209822699 0.05227563496039377\n",
      "13 0.03312195053248766 0.05117278825814095\n",
      "14 0.034899879891482286 0.0426519609902003\n",
      "15 0.025113375162007255 0.03985696482785238\n",
      "16 0.031628826066188755 0.04266884652952742\n",
      "17 0.027995357440242716 0.047439949356599995\n",
      "18 0.033382047463223576 0.0421281882526685\n",
      "19 0.03437315819703424 0.05961349356876301\n",
      "20 0.031401038909475626 0.0523975706886006\n",
      "21 0.02822860716068578 0.04594070237042509\n",
      "22 0.03903883548866728 0.04732787610639706\n",
      "23 0.028323736534994932 0.043624693634093444\n",
      "24 0.02744032015050452 0.04398422772202417\n",
      "25 0.029173432025729296 0.04319394459780999\n",
      "26 0.03421687263368461 0.047755596584264995\n",
      "27 0.030573939311890074 0.048325812021535734\n",
      "28 0.027451580915435127 0.05033683889062189\n",
      "29 0.026730110108349928 0.050300515235212916\n",
      "30 0.02839627949108707 0.04788260626212086\n",
      "31 0.03857742156977477 0.05147296609260153\n",
      "32 0.029189084362207705 0.052871620571103645\n",
      "33 0.02919964428808365 0.042314768131792774\n",
      "34 0.028631304041952046 0.043697738264603825\n",
      "35 0.0305781949854923 0.049097565921534296\n",
      "36 0.029992751968640003 0.04773748110858084\n",
      "37 0.027032842250285183 0.039273351502187664\n",
      "38 0.028536097150827548 0.04417395756221146\n",
      "39 0.024951890107753852 0.05324336183464825\n",
      "40 0.03481963114624361 0.046530264709286805\n",
      "41 0.032849830252490914 0.038142552428476376\n",
      "42 0.02508486143591947 0.04521759193916878\n",
      "43 0.03518938495040707 0.05523075429652397\n",
      "44 0.02809231978062238 0.03996070375053898\n",
      "45 0.030394830867153052 0.050165054581050215\n",
      "46 0.04580109749221883 0.05679332531446251\n",
      "47 0.027243745247538958 0.04423580386407899\n",
      "48 0.029223567254218267 0.04017619206442856\n",
      "49 0.03832716308719084 0.05277231426272676\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "num_exp = 50\n",
    "result_mse = np.zeros((num_exp, 2))\n",
    "for exp in range(num_exp):\n",
    "    random.seed(exp)\n",
    "    torch.manual_seed(exp)\n",
    "    np.random.seed(exp)\n",
    "    #####################################################################\n",
    "    # generate images\n",
    "    train_idx = np.random.choice(train_idx_all, size = n_train, replace = False)\n",
    "    test_idx = np.random.choice(test_idx_all, size = n_test, replace = False)\n",
    "\n",
    "    train_imgs = train_img[train_idx, ]\n",
    "    test_imgs = test_img[test_idx, ]\n",
    "\n",
    "    train_quantiles = np.zeros((4, n_train))\n",
    "    for i in range(n_train):\n",
    "        train_img_i = train_imgs[i, :]\n",
    "        train_img_i = train_img_i[train_img_i > 0]\n",
    "        train_quantiles[:, i] = np.quantile(train_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "    train_q0 = np.tile(train_quantiles[0, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q1 = np.tile(train_quantiles[1, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q2 = np.tile(train_quantiles[2, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q3 = np.tile(train_quantiles[3, :].reshape((n_train, 1)), (1, 784))\n",
    "\n",
    "    train_p0 = np.zeros((n_train, 784))\n",
    "    train_p1 = np.zeros((n_train, 784))\n",
    "    train_p2 = np.zeros((n_train, 784))\n",
    "    train_p3 = np.zeros((n_train, 784))\n",
    "\n",
    "    train_p3[train_imgs >= train_q3] = train_imgs[train_imgs >= train_q3]\n",
    "    train_p2[(train_imgs >= train_q2) & (train_imgs < train_q3)] = train_imgs[(train_imgs >= train_q2) & (train_imgs < train_q3)]\n",
    "    train_p1[(train_imgs >= train_q1) & (train_imgs < train_q2)] = train_imgs[(train_imgs >= train_q1) & (train_imgs < train_q2)]\n",
    "    train_p0[(train_imgs >= train_q0) & (train_imgs < train_q1)] = train_imgs[(train_imgs >= train_q0) & (train_imgs < train_q1)]\n",
    "\n",
    "    train_predictors = np.zeros((n_train, 28*28*4))\n",
    "    train_outcomes = train_imgs\n",
    "    train_outcomes_padding = np.zeros((n_train, 28*28*4))\n",
    "    for i in range(n_train):\n",
    "        train_p0_i = train_p0[i, :].reshape((28, 28))\n",
    "        train_p1_i = train_p1[i, :].reshape((28, 28))\n",
    "        train_p2_i = train_p2[i, :].reshape((28, 28))\n",
    "        train_p3_i = train_p3[i, :].reshape((28, 28))\n",
    "        train_predictor_i = np.hstack((train_p0_i, train_p1_i, train_p2_i, train_p3_i))\n",
    "        train_predictors[i, :] = train_predictor_i.reshape(-1)\n",
    "        train_outcome_i = train_outcomes[i, :].reshape((28, 28))\n",
    "        train_outcomes_padding[i, :] = np.hstack((np.zeros((28, 42)), train_outcome_i, np.zeros((28, 42)))).reshape(-1)\n",
    "        \n",
    "        \n",
    "    test_quantiles = np.zeros((4, n_test))\n",
    "    for i in range(n_test):\n",
    "        test_img_i = test_imgs[i, :]\n",
    "        test_img_i = test_img_i[test_img_i > 0]\n",
    "        test_quantiles[:, i] = np.quantile(test_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "    test_q0 = np.tile(test_quantiles[0, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q1 = np.tile(test_quantiles[1, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q2 = np.tile(test_quantiles[2, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q3 = np.tile(test_quantiles[3, :].reshape((n_test, 1)), (1, 784))\n",
    "\n",
    "    test_p0 = np.zeros((n_test, 784))\n",
    "    test_p1 = np.zeros((n_test, 784))\n",
    "    test_p2 = np.zeros((n_test, 784))\n",
    "    test_p3 = np.zeros((n_test, 784))\n",
    "\n",
    "    test_p3[test_imgs >= test_q3] = test_imgs[test_imgs >= test_q3]\n",
    "    test_p2[(test_imgs >= test_q2) & (test_imgs < test_q3)] = test_imgs[(test_imgs >= test_q2) & (test_imgs < test_q3)]\n",
    "    test_p1[(test_imgs >= test_q1) & (test_imgs < test_q2)] = test_imgs[(test_imgs >= test_q1) & (test_imgs < test_q2)]\n",
    "    test_p0[(test_imgs >= test_q0) & (test_imgs < test_q1)] = test_imgs[(test_imgs >= test_q0) & (test_imgs < test_q1)]\n",
    "\n",
    "    test_predictors = np.zeros((n_test, 28*28*4))\n",
    "    test_outcomes = test_imgs\n",
    "    test_outcomes_padding = np.zeros((n_test, 28*28*4))\n",
    "    for i in range(n_test):\n",
    "        test_p0_i = test_p0[i, :].reshape((28, 28))\n",
    "        test_p1_i = test_p1[i, :].reshape((28, 28))\n",
    "        test_p2_i = test_p2[i, :].reshape((28, 28))\n",
    "        test_p3_i = test_p3[i, :].reshape((28, 28))\n",
    "        test_predictor_i = np.hstack((test_p0_i, test_p1_i, test_p2_i, test_p3_i))\n",
    "        test_predictors[i, :] = test_predictor_i.reshape(-1)\n",
    "        test_outcome_i = test_outcomes[i, :].reshape((28, 28))\n",
    "        test_outcomes_padding[i, :] = np.hstack((np.zeros((28, 42)), test_outcome_i, np.zeros((28, 42)))).reshape(-1)\n",
    "\n",
    "    np.savetxt(\"train_predictors.txt\", train_predictors)\n",
    "    np.savetxt(\"test_predictors.txt\", test_predictors)\n",
    "    np.savetxt(\"train_outcomes.txt\", train_outcomes)\n",
    "    np.savetxt(\"test_outcomes.txt\", test_outcomes)\n",
    "\n",
    "    rbdn = RBDN(num_channels).to(\"cuda\")\n",
    "    rbdn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 1, 28, 112)).to(\"cuda\")\n",
    "    rbdn_train_outcomes = torch.tensor(train_outcomes_padding, dtype = torch.float32).reshape((n_train, 1, 28, 112)).to(\"cuda\")\n",
    "    rbdn_loss = nn.functional.mse_loss\n",
    "    rbdn_optim = torch.optim.Adam(rbdn.parameters(), lr = 1e-3)\n",
    "\n",
    "    rbdn_dataset = Dataset(rbdn_train_predictors, rbdn_train_outcomes)\n",
    "    rbdn_dataloader = torch.utils.data.DataLoader(rbdn_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 50\n",
    "    rbdn.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(rbdn_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = rbdn(X_batch)             \n",
    "            loss = rbdn_loss(output, y_batch)\n",
    "\n",
    "            rbdn_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            rbdn_optim.step()\n",
    "    \n",
    "    rbdn_train_predictors = rbdn_train_predictors.to(\"cpu\")\n",
    "    rbdn = rbdn.to(\"cpu\")\n",
    "\n",
    "    rbdn_train_pred = rbdn(rbdn_train_predictors)\n",
    "    rbdn_test_pred = rbdn(torch.tensor(test_predictors, dtype = torch.float32).reshape((n_test, 1, 28, 112)))\n",
    "\n",
    "    rbdn_train_pred = rbdn_train_pred[:, :, :, 42:70]\n",
    "    rbdn_test_pred = rbdn_test_pred[:, :, :, 42:70]\n",
    "\n",
    "    result_mse[exp, 0] = np.mean((rbdn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 1] = np.mean((rbdn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "    print(exp, result_mse[exp, 0], result_mse[exp, 1])\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    np.savetxt(\"result_mse_rbdn.txt\", result_mse)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "digits-rbdn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
