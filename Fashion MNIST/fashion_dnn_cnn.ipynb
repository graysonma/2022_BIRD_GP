{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f",
   "metadata": {
    "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class BFNN(torch.nn.Module):\n",
    "    def __init__(self, d, L, n, V):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.L = L\n",
    "        self.n = n\n",
    "        self.V = V\n",
    "        self.theta = torch.nn.Parameter(torch.randn(self.n, self.L))\n",
    "\n",
    "        # define layers\n",
    "        #self.num_nodes = num_nodes\n",
    "        #self.layers = []\n",
    "        #for i in range(len(num_nodes)):\n",
    "        #  if i == 0:\n",
    "        #    self.layers.append(torch.nn.Linear(self.d, num_nodes[0]))\n",
    "        #  else:\n",
    "        #    self.layers.append(torch.nn.Linear(num_nodes[i-1], num_nodes[i]))\n",
    "        #self.layers.append(torch.nn.Linear(num_nodes[-1], L))\n",
    "        self.layer1 = torch.nn.Linear(d, 128)\n",
    "        self.layer2 = torch.nn.Linear(128, 128)\n",
    "        self.layer3 = torch.nn.Linear(128, 128)\n",
    "        self.layer4 = torch.nn.Linear(128, 128)\n",
    "        self.layerL = torch.nn.Linear(128, L)\n",
    "\n",
    "        # define activation functions\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        #for i in range(len(self.num_nodes)):\n",
    "        #  X = self.layers[i](X)\n",
    "        #  X = self.relu(X)\n",
    "        #self.Psi = self.layers[-1](X)\n",
    "\n",
    "        X = self.layer1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.layer2(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.layer3(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.layer4(X)\n",
    "        X = self.relu(X)\n",
    "        self.Psi = self.layerL(X)\n",
    "        self.yhat = self.theta @ self.Psi.t() \n",
    "        return self.yhat\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Linear(in_dim, 200), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.body(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, predictors, labels):\n",
    "        self.labels = labels\n",
    "        self.predictors = predictors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.predictors[index, :]\n",
    "        y = self.labels[index, :]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class DNN_FB1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28*4,64)\n",
    "        self.linear2 = nn.Linear(64, 784)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)                    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DNN_FB2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28*4, 256)\n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.linear3 = nn.Linear(256, 256)\n",
    "        self.linear4 = nn.Linear(256, 784)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)                    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "  \n",
    "class DNN_FB3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28*4, 256)\n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.linear3 = nn.Linear(256, 256)\n",
    "        self.linear4 = nn.Linear(256, 256)\n",
    "        self.linear5 = nn.Linear(256, 784)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)                    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_FB1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(1, 64, 3, 1, \"same\"),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size = 2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 64, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.linear1 = nn.Linear(1344, 64)\n",
    "        self.linear2 = nn.Linear(64, 784)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "                                 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)      \n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_FB2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(1, 64, 3, 1, \"same\"),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size = 2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.linear1 = nn.Linear(224, 64)\n",
    "        self.linear2 = nn.Linear(64, 784)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "                                 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)      \n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_FB3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(1, 128, 3, 1, \"same\"),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size = 2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(128, 64, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(64, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 32, 3, 1, \"same\"),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.linear1 = nn.Linear(224, 128)\n",
    "        self.linear2 = nn.Linear(128, 784)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "                                 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(x.size(0), -1)      \n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5hVNCWzmsCHc",
   "metadata": {
    "id": "5hVNCWzmsCHc"
   },
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"drive/MyDrive/Image-on-image/fashion-mnist_train.csv\", skiprows = 1, delimiter = \",\")\n",
    "test_data = np.loadtxt(\"drive/MyDrive/Image-on-image/fashion-mnist_test.csv\", skiprows = 1, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b",
   "metadata": {
    "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b"
   },
   "outputs": [],
   "source": [
    "train_img = train_data[:, 1:]\n",
    "test_img = test_data[:, 1:]\n",
    "train_label = train_data[:, 0]\n",
    "test_label = test_data[:, 0]\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255\n",
    "\n",
    "train_idx_all = np.arange(60000)\n",
    "test_idx_all = np.arange(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3484197,
     "status": "ok",
     "timestamp": 1651769794899,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "01247bb0-324a-4303-e51d-2d810b4e1752",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.03296    0.03548689 0.02441296 0.03077975 0.02348682 0.03141908\n",
      " 0.03334156 0.03583363 0.03194693 0.03381022 0.02765244 0.03072159]\n",
      "1 [0.03550629 0.03799066 0.02469931 0.03079765 0.02377388 0.03118394\n",
      " 0.03445708 0.03615464 0.03222535 0.03396915 0.02678506 0.03072729]\n",
      "2 [0.03573148 0.03779202 0.02429193 0.03174366 0.02408021 0.03181109\n",
      " 0.03602284 0.03691211 0.0326391  0.03478409 0.02585895 0.02997194]\n",
      "3 [0.03360248 0.03719071 0.02513809 0.03123808 0.02373358 0.03168854\n",
      " 0.03757319 0.03782762 0.03467136 0.03626028 0.02688839 0.03012135]\n",
      "4 [0.03251413 0.03619206 0.02327208 0.03043711 0.0233788  0.03063147\n",
      " 0.03112825 0.03342431 0.03283055 0.03498458 0.02545366 0.02939157]\n",
      "5 [0.03400903 0.0367688  0.02446848 0.03124658 0.02431307 0.03097129\n",
      " 0.03497571 0.03602101 0.03402826 0.0354158  0.02629529 0.03010443]\n",
      "6 [0.03186642 0.03567079 0.02399054 0.0314806  0.02320139 0.03127043\n",
      " 0.0331852  0.0363152  0.03194597 0.03527632 0.02589132 0.0301259 ]\n",
      "7 [0.0336531  0.03694876 0.02433081 0.03104167 0.02408759 0.03173762\n",
      " 0.03537374 0.03710027 0.03163949 0.03425648 0.02704803 0.03051802]\n",
      "8 [0.03261074 0.03442772 0.02447456 0.03023436 0.02382609 0.0301345\n",
      " 0.03482871 0.03617944 0.03334556 0.0350536  0.0266592  0.02954803]\n",
      "9 [0.03352124 0.03681825 0.02423933 0.03052394 0.02382956 0.0311865\n",
      " 0.03735709 0.03830546 0.03326034 0.03484801 0.02664983 0.02965049]\n",
      "10 [0.03281103 0.03611989 0.02407991 0.03036232 0.02325216 0.03090677\n",
      " 0.03545515 0.03681785 0.03193061 0.0340566  0.02633635 0.0298311 ]\n",
      "11 [0.03484569 0.03610207 0.02434962 0.03098116 0.02394537 0.03126176\n",
      " 0.03643891 0.03823107 0.03359386 0.03531992 0.02805305 0.03146798]\n",
      "12 [0.03513426 0.03925287 0.0237092  0.03032067 0.02369435 0.02998608\n",
      " 0.0362904  0.03760668 0.0323484  0.03423688 0.02706498 0.0302655 ]\n",
      "13 [0.03414576 0.03751451 0.02457004 0.03128834 0.02382044 0.03125286\n",
      " 0.03361007 0.03633521 0.03106194 0.03413195 0.02662893 0.03024239]\n",
      "14 [0.03409436 0.03668198 0.02440946 0.0300541  0.02386056 0.03057208\n",
      " 0.03432507 0.0364063  0.03269936 0.0338111  0.02562635 0.02901019]\n",
      "15 [0.03395012 0.03789294 0.0245572  0.03090906 0.02389227 0.03106472\n",
      " 0.03433666 0.03639877 0.0324824  0.03501672 0.02571559 0.02930733]\n",
      "16 [0.0344747  0.03701443 0.02463188 0.0305691  0.02430857 0.03114646\n",
      " 0.037566   0.03921107 0.03259661 0.03412093 0.02650573 0.0291914 ]\n",
      "17 [0.03160166 0.03477848 0.02418041 0.03255366 0.02364154 0.03174767\n",
      " 0.03361201 0.03611225 0.03311563 0.03520862 0.02640028 0.03042447]\n",
      "18 [0.032198   0.03507405 0.02396456 0.03009096 0.02399077 0.03068314\n",
      " 0.03562475 0.03697409 0.03278672 0.03480178 0.02708551 0.02986927]\n",
      "19 [0.03727018 0.0400051  0.02419637 0.03079542 0.02378641 0.03151493\n",
      " 0.03326303 0.03558717 0.03147827 0.03435201 0.0266365  0.03069303]\n",
      "20 [0.03088796 0.035789   0.02372886 0.02984821 0.02330778 0.03069416\n",
      " 0.03449592 0.03701872 0.03257431 0.03538126 0.02536632 0.02908161]\n",
      "21 [0.03401595 0.03631857 0.02552441 0.03059745 0.02397382 0.03047489\n",
      " 0.03461134 0.03604924 0.03179182 0.03392964 0.02735075 0.03006173]\n",
      "22 [0.04073802 0.04027062 0.0252844  0.03039132 0.02436778 0.03098697\n",
      " 0.03878442 0.03877131 0.03245639 0.03333956 0.02759441 0.02988926]\n",
      "23 [0.03692117 0.03733232 0.02447819 0.03078763 0.02395314 0.03019488\n",
      " 0.03425608 0.0349798  0.03257492 0.03387526 0.02831504 0.03093872]\n",
      "24 [0.03315483 0.03627403 0.02435255 0.03067096 0.02386215 0.03129498\n",
      " 0.03574762 0.03668281 0.03327901 0.03455417 0.02816958 0.03086204]\n",
      "25 [0.03267573 0.03473697 0.02377787 0.02959416 0.02325606 0.02996505\n",
      " 0.03444348 0.03558805 0.03194223 0.03438518 0.02579405 0.02928539]\n",
      "26 [0.03423479 0.03735206 0.02469874 0.03072442 0.02453933 0.03242256\n",
      " 0.03356006 0.03501486 0.03229323 0.03381888 0.0269061  0.02978683]\n",
      "27 [0.03434582 0.03741215 0.02399732 0.03042965 0.02365812 0.03135452\n",
      " 0.03785821 0.03935213 0.03269758 0.03510425 0.02731358 0.03116445]\n",
      "28 [0.03639969 0.03816103 0.02488096 0.03076811 0.02461055 0.03055528\n",
      " 0.03313904 0.03403926 0.03380845 0.03475481 0.02726518 0.03041116]\n",
      "29 [0.03373134 0.03681448 0.02392448 0.03069523 0.02325428 0.03049281\n",
      " 0.03543458 0.03733908 0.03188366 0.03424534 0.02597822 0.02999558]\n",
      "30 [0.03519647 0.03771189 0.02411076 0.0307401  0.02350859 0.03148188\n",
      " 0.03384366 0.03619584 0.03168332 0.0346927  0.02680182 0.03082647]\n",
      "31 [0.03512033 0.03670076 0.02449877 0.03020028 0.02428011 0.02987988\n",
      " 0.03515064 0.03589583 0.03269634 0.03451625 0.02772986 0.02985726]\n",
      "32 [0.03255456 0.03596988 0.02394597 0.03072129 0.02360611 0.03146539\n",
      " 0.03547443 0.03810995 0.03231384 0.03456641 0.02574456 0.02970979]\n",
      "33 [0.03351549 0.03587904 0.0238284  0.03012997 0.02340364 0.03068168\n",
      " 0.03432031 0.03542716 0.03264383 0.03422309 0.02609243 0.02956168]\n",
      "34 [0.0349498  0.03694286 0.0239808  0.03017557 0.02361316 0.03057641\n",
      " 0.03615599 0.03756421 0.03183581 0.0330806  0.02709412 0.02997127]\n",
      "35 [0.03533365 0.03734212 0.02428751 0.02990768 0.02412657 0.03083823\n",
      " 0.03687577 0.03904519 0.03258901 0.03413814 0.02734086 0.0298259 ]\n",
      "36 [0.03234661 0.03421112 0.02549861 0.03072287 0.02466664 0.03136562\n",
      " 0.03544386 0.03547354 0.03345562 0.03410412 0.02722078 0.03016458]\n",
      "37 [0.0362254  0.03781538 0.02511306 0.03057366 0.02430655 0.03091184\n",
      " 0.03604196 0.03647831 0.03263797 0.03398731 0.02730973 0.03021703]\n",
      "38 [0.03438446 0.03664315 0.02387    0.03039071 0.02351815 0.03128844\n",
      " 0.03232678 0.03365578 0.03159416 0.03349838 0.02707454 0.03031545]\n",
      "39 [0.03300323 0.0360486  0.02390328 0.03065451 0.02362503 0.0317084\n",
      " 0.0332633  0.03541704 0.03096278 0.03337532 0.02822646 0.03143015]\n",
      "40 [0.03115646 0.03498285 0.0236914  0.02999862 0.02286996 0.03054721\n",
      " 0.03279518 0.03519828 0.0297861  0.03309676 0.0264281  0.03050294]\n",
      "41 [0.03446013 0.03596319 0.02415288 0.02995141 0.02410009 0.03028757\n",
      " 0.03253121 0.03420299 0.03261459 0.03385561 0.02593958 0.02861267]\n",
      "42 [0.0338567  0.03776214 0.02317788 0.03044829 0.02268427 0.03086585\n",
      " 0.03308671 0.03512357 0.03133713 0.03343621 0.02473583 0.02852284]\n",
      "43 [0.03249262 0.0343962  0.02383814 0.03002704 0.02386024 0.03042977\n",
      " 0.03410859 0.03507959 0.03136602 0.03254733 0.0267985  0.0294577 ]\n",
      "44 [0.03422402 0.03704893 0.02492349 0.03075295 0.02359192 0.03093766\n",
      " 0.03501252 0.03721148 0.0325504  0.03401053 0.02614317 0.02966449]\n",
      "45 [0.03337694 0.0360725  0.02412276 0.0311069  0.02371514 0.03103638\n",
      " 0.03363216 0.03507512 0.03118973 0.03331378 0.02632805 0.02971447]\n",
      "46 [0.03532495 0.03626781 0.02387635 0.02953405 0.02330559 0.03037982\n",
      " 0.03304014 0.03379147 0.03179954 0.03311312 0.02586773 0.02911466]\n",
      "47 [0.0366274  0.03982327 0.02471008 0.02997613 0.02393548 0.03080737\n",
      " 0.03381123 0.03587301 0.03398936 0.03561587 0.02635393 0.02986586]\n",
      "48 [0.03520102 0.03825931 0.02438361 0.03116497 0.02408247 0.03069825\n",
      " 0.03740596 0.0380838  0.03240521 0.03471016 0.02800209 0.03113672]\n",
      "49 [0.03140983 0.03508645 0.02400395 0.03091343 0.02372144 0.03189408\n",
      " 0.03621975 0.03881877 0.03235522 0.0341914  0.02622473 0.02975982]\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "num_exp = 50\n",
    "result_mse = np.zeros((num_exp, 12))\n",
    "L = 50\n",
    "for exp in range(num_exp):\n",
    "    random.seed(exp)\n",
    "    torch.manual_seed(exp)\n",
    "    np.random.seed(exp)\n",
    "    #####################################################################\n",
    "    # generate images\n",
    "    train_idx = np.random.choice(train_idx_all, size = n_train, replace = False)\n",
    "    test_idx = np.random.choice(test_idx_all, size = n_test, replace = False)\n",
    "\n",
    "    train_imgs = train_img[train_idx, ]\n",
    "    test_imgs = test_img[test_idx, ]\n",
    "\n",
    "    train_quantiles = np.zeros((4, n_train))\n",
    "    for i in range(n_train):\n",
    "        train_img_i = train_imgs[i, :]\n",
    "        train_img_i = train_img_i[train_img_i > 0]\n",
    "        train_quantiles[:, i] = np.quantile(train_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "    train_q0 = np.tile(train_quantiles[0, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q1 = np.tile(train_quantiles[1, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q2 = np.tile(train_quantiles[2, :].reshape((n_train, 1)), (1, 784))\n",
    "    train_q3 = np.tile(train_quantiles[3, :].reshape((n_train, 1)), (1, 784))\n",
    "\n",
    "    train_p0 = np.zeros((n_train, 784))\n",
    "    train_p1 = np.zeros((n_train, 784))\n",
    "    train_p2 = np.zeros((n_train, 784))\n",
    "    train_p3 = np.zeros((n_train, 784))\n",
    "\n",
    "    train_p3[train_imgs >= train_q3] = train_imgs[train_imgs >= train_q3]\n",
    "    train_p2[(train_imgs >= train_q2) & (train_imgs < train_q3)] = train_imgs[(train_imgs >= train_q2) & (train_imgs < train_q3)]\n",
    "    train_p1[(train_imgs >= train_q1) & (train_imgs < train_q2)] = train_imgs[(train_imgs >= train_q1) & (train_imgs < train_q2)]\n",
    "    train_p0[(train_imgs >= train_q0) & (train_imgs < train_q1)] = train_imgs[(train_imgs >= train_q0) & (train_imgs < train_q1)]\n",
    "\n",
    "    train_predictors = np.zeros((n_train, 28*28*4))\n",
    "    train_outcomes = train_imgs\n",
    "    for i in range(n_train):\n",
    "        train_p0_i = train_p0[i, :].reshape((28, 28))\n",
    "        train_p1_i = train_p1[i, :].reshape((28, 28))\n",
    "        train_p2_i = train_p2[i, :].reshape((28, 28))\n",
    "        train_p3_i = train_p3[i, :].reshape((28, 28))\n",
    "        train_predictor_i = np.hstack((train_p0_i, train_p1_i, train_p2_i, train_p3_i))\n",
    "        train_predictors[i, :] = train_predictor_i.reshape(-1)\n",
    "\n",
    "    test_quantiles = np.zeros((4, n_test))\n",
    "    for i in range(n_test):\n",
    "        test_img_i = test_imgs[i, :]\n",
    "        test_img_i = test_img_i[test_img_i > 0]\n",
    "        test_quantiles[:, i] = np.quantile(test_img_i, [0, 0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "    test_q0 = np.tile(test_quantiles[0, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q1 = np.tile(test_quantiles[1, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q2 = np.tile(test_quantiles[2, :].reshape((n_test, 1)), (1, 784))\n",
    "    test_q3 = np.tile(test_quantiles[3, :].reshape((n_test, 1)), (1, 784))\n",
    "\n",
    "    test_p0 = np.zeros((n_test, 784))\n",
    "    test_p1 = np.zeros((n_test, 784))\n",
    "    test_p2 = np.zeros((n_test, 784))\n",
    "    test_p3 = np.zeros((n_test, 784))\n",
    "\n",
    "    test_p3[test_imgs >= test_q3] = test_imgs[test_imgs >= test_q3]\n",
    "    test_p2[(test_imgs >= test_q2) & (test_imgs < test_q3)] = test_imgs[(test_imgs >= test_q2) & (test_imgs < test_q3)]\n",
    "    test_p1[(test_imgs >= test_q1) & (test_imgs < test_q2)] = test_imgs[(test_imgs >= test_q1) & (test_imgs < test_q2)]\n",
    "    test_p0[(test_imgs >= test_q0) & (test_imgs < test_q1)] = test_imgs[(test_imgs >= test_q0) & (test_imgs < test_q1)]\n",
    "\n",
    "    test_predictors = np.zeros((n_test, 28*28*4))\n",
    "    test_outcomes = test_imgs\n",
    "    for i in range(n_test):\n",
    "        test_p0_i = test_p0[i, :].reshape((28, 28))\n",
    "        test_p1_i = test_p1[i, :].reshape((28, 28))\n",
    "        test_p2_i = test_p2[i, :].reshape((28, 28))\n",
    "        test_p3_i = test_p3[i, :].reshape((28, 28))\n",
    "        test_predictor_i = np.hstack((test_p0_i, test_p1_i, test_p2_i, test_p3_i))\n",
    "        test_predictors[i, :] = test_predictor_i.reshape(-1)\n",
    "\n",
    "    np.savetxt(\"train_predictors.txt\", train_predictors)\n",
    "    np.savetxt(\"test_predictors.txt\", test_predictors)\n",
    "    np.savetxt(\"train_outcomes.txt\", train_outcomes)\n",
    "    np.savetxt(\"test_outcomes.txt\", test_outcomes)\n",
    "\n",
    "    #####################################################################\n",
    "    # DNN1\n",
    "    dnn_fb = DNN_FB1().to(\"cuda\")\n",
    "    dnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 28*112)).to(\"cuda\")\n",
    "    dnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    dnn_fb_loss = nn.functional.mse_loss\n",
    "    dnn_fb_optim = torch.optim.Adam(dnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    dnn_fb_dataset = Dataset(dnn_train_predictors, dnn_train_outcomes)\n",
    "    dnn_fb_dataloader = torch.utils.data.DataLoader(dnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    dnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(dnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = dnn_fb(X_batch)             \n",
    "            loss = dnn_fb_loss(output, y_batch)\n",
    "\n",
    "            dnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            dnn_fb_optim.step()            \n",
    "\n",
    "    dnn_train_pred = dnn_fb(dnn_train_predictors).reshape((n_train, 1, 28, 28)).to(\"cuda\")\n",
    "    dnn_test_pred = dnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 28*112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 0] = np.mean((dnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2) \n",
    "    result_mse[exp, 1] = np.mean((dnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    # DNN2\n",
    "    dnn_fb = DNN_FB2().to(\"cuda\")\n",
    "    dnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 28*112)).to(\"cuda\")\n",
    "    dnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    dnn_fb_loss = nn.functional.mse_loss\n",
    "    dnn_fb_optim = torch.optim.Adam(dnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    dnn_fb_dataset = Dataset(dnn_train_predictors, dnn_train_outcomes)\n",
    "    dnn_fb_dataloader = torch.utils.data.DataLoader(dnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    dnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(dnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = dnn_fb(X_batch)             \n",
    "            loss = dnn_fb_loss(output, y_batch)\n",
    "\n",
    "            dnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            dnn_fb_optim.step()            \n",
    "\n",
    "    dnn_train_pred = dnn_fb(dnn_train_predictors).reshape((n_train, 1, 28, 28))\n",
    "    dnn_test_pred = dnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 28*112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 2] = np.mean((dnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 3] = np.mean((dnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    # DNN3\n",
    "    dnn_fb = DNN_FB3().to(\"cuda\")\n",
    "    dnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 28*112)).to(\"cuda\")\n",
    "    dnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    dnn_fb_loss = nn.functional.mse_loss\n",
    "    dnn_fb_optim = torch.optim.Adam(dnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    dnn_fb_dataset = Dataset(dnn_train_predictors, dnn_train_outcomes)\n",
    "    dnn_fb_dataloader = torch.utils.data.DataLoader(dnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 200\n",
    "    dnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(dnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = dnn_fb(X_batch)             \n",
    "            loss = dnn_fb_loss(output, y_batch)\n",
    "\n",
    "            dnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            dnn_fb_optim.step()            \n",
    "\n",
    "    dnn_train_pred = dnn_fb(dnn_train_predictors).reshape((n_train, 1, 28, 28))\n",
    "    dnn_test_pred = dnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 28*112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 4] = np.mean((dnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 5] = np.mean((dnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "    #####################################################################\n",
    "    # CNN1\n",
    "    cnn_fb = CNN_FB1().to(\"cuda\")\n",
    "    cnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 1, 28, 112)).to(\"cuda\")\n",
    "    cnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    cnn_fb_loss = nn.functional.mse_loss\n",
    "    cnn_fb_optim = torch.optim.Adam(cnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    cnn_fb_dataset = Dataset(cnn_train_predictors, cnn_train_outcomes)\n",
    "    cnn_fb_dataloader = torch.utils.data.DataLoader(cnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    cnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(cnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = cnn_fb(X_batch)             \n",
    "            loss = cnn_fb_loss(output, y_batch)\n",
    "\n",
    "            cnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            cnn_fb_optim.step()            \n",
    "\n",
    "    cnn_train_pred = cnn_fb(cnn_train_predictors).reshape((n_train, 1, 28, 28))\n",
    "    cnn_test_pred = cnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 1, 28, 112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 6] = np.mean((cnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 7] = np.mean((cnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "    #####################################################################\n",
    "    # CNN2\n",
    "    cnn_fb = CNN_FB2().to(\"cuda\")\n",
    "    cnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 1, 28, 112)).to(\"cuda\")\n",
    "    cnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    cnn_fb_loss = nn.functional.mse_loss\n",
    "    cnn_fb_optim = torch.optim.Adam(cnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    cnn_fb_dataset = Dataset(cnn_train_predictors, cnn_train_outcomes)\n",
    "    cnn_fb_dataloader = torch.utils.data.DataLoader(cnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    cnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(cnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = cnn_fb(X_batch)             \n",
    "            loss = cnn_fb_loss(output, y_batch)\n",
    "\n",
    "            cnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            cnn_fb_optim.step()            \n",
    "\n",
    "    cnn_train_pred = cnn_fb(cnn_train_predictors).reshape((n_train, 1, 28, 28))\n",
    "    cnn_test_pred = cnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 1, 28, 112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 8] = np.mean((cnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 9] = np.mean((cnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    # CNN3\n",
    "    cnn_fb = CNN_FB3().to(\"cuda\")\n",
    "    cnn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 1, 28, 112)).to(\"cuda\")\n",
    "    cnn_train_outcomes = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 784)).to(\"cuda\")\n",
    "    cnn_fb_loss = nn.functional.mse_loss\n",
    "    cnn_fb_optim = torch.optim.Adam(cnn_fb.parameters(), lr = 1e-3)\n",
    "\n",
    "    cnn_fb_dataset = Dataset(cnn_train_predictors, cnn_train_outcomes)\n",
    "    cnn_fb_dataloader = torch.utils.data.DataLoader(cnn_fb_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    cnn_fb.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(cnn_fb_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = cnn_fb(X_batch)             \n",
    "            loss = cnn_fb_loss(output, y_batch)\n",
    "\n",
    "            cnn_fb_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            cnn_fb_optim.step()            \n",
    "\n",
    "    cnn_train_pred = cnn_fb(cnn_train_predictors).reshape((n_train, 1, 28, 28))\n",
    "    cnn_test_pred = cnn_fb(torch.tensor(test_predictors, dtype = torch.float32).to(\"cuda\").reshape((n_test, 1, 28, 112))).reshape((n_test, 1, 28, 28))\n",
    "\n",
    "    result_mse[exp, 10] = np.mean((cnn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 11] = np.mean((cnn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "    print(exp, result_mse[exp, :])\n",
    "\n",
    "np.savetxt(\"result_mse.txt\", result_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476ca8d-5da7-47b1-be66-bd90add8a5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1651764733927,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "c476ca8d-5da7-47b1-be66-bd90add8a5b1",
    "outputId": "6d91a3b2-d4e5-4dfa-b439-c084a7bae1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN_FB1()\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uigtcvao2Qa9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1651764734495,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "Uigtcvao2Qa9",
    "outputId": "f10ae0ec-6972-483c-dd23-8a605cd5a95b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN_FB2()\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rrHVF9_C2SOn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1651764735140,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "rrHVF9_C2SOn",
    "outputId": "80d5bea8-36ea-480f-e3d2-3ae6264daf52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201936"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN_FB3()\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sGQyW2ls2TbF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100,
     "status": "ok",
     "timestamp": 1651764735745,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "sGQyW2ls2TbF",
    "outputId": "b6238804-9c1a-4938-8c85-37df39381ee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_FB1()\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o5CQ-NWZ2V2z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1651764736615,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "o5CQ-NWZ2V2z",
    "outputId": "2b6a674c-09ac-40e9-cfba-f5fd438e9726"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102960"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_FB2()\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LJ1xAE2W2W6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1651764738279,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "LJ1xAE2W2W6a",
    "outputId": "31e1a74b-6f5a-486c-8d7a-807a4b36db2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232720"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_FB3()\n",
    "sum([p.nume2l() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v0vg5Rns2vaO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1651764836566,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "v0vg5Rns2vaO",
    "outputId": "af38f23b-3714-42b6-dced-b3ad7aef23e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106370"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BFNN(d = 2, L = 50, n = 1000, V = 28*28*4)\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SaIhroVv2beQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1651764984425,
     "user": {
      "displayName": "Grayson Ma",
      "userId": "13881155814468576674"
     },
     "user_tz": 240
    },
    "id": "SaIhroVv2beQ",
    "outputId": "5cf07819-aa76-49e9-b15d-de059e2ad303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(50, 50)\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5QD2M28i2q1g",
   "metadata": {
    "id": "5QD2M28i2q1g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "fashion-nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
