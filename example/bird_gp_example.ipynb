{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## BIRD-GP: A Synthesized Fashion MNIST Example"
      ],
      "metadata": {
        "id": "NcYSkmesslU6"
      },
      "id": "NcYSkmesslU6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install from Github"
      ],
      "metadata": {
        "id": "xmTiObTxr95l"
      },
      "id": "xmTiObTxr95l"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/guoxuan-ma/2022_BIRD_GP"
      ],
      "metadata": {
        "id": "YXW7X312rXo0"
      },
      "id": "YXW7X312rXo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f",
      "metadata": {
        "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import bird_gp\n",
        "import random\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0d12d9-ea66-45e7-988f-9ed60cdd20f9",
      "metadata": {
        "id": "cb0d12d9-ea66-45e7-988f-9ed60cdd20f9"
      },
      "source": [
        "### Read images and generate synthesized images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d07d7ae7-0631-49fb-a972-cc294dbf18c0",
      "metadata": {
        "id": "d07d7ae7-0631-49fb-a972-cc294dbf18c0"
      },
      "outputs": [],
      "source": [
        "#####################################################################\n",
        "# read images\n",
        "train_data = np.loadtxt(\"fashion_mnist_train_example_data.txt\")\n",
        "test_data = np.loadtxt(\"fashion_mnist_test_example_data.txt\")\n",
        "\n",
        "train_imgs = train_data[:, 1:]\n",
        "test_imgs = test_data[:, 1:]\n",
        "train_lbs = train_data[:, 0]\n",
        "test_lbs = test_data[:, 0]\n",
        "train_imgs = train_imgs / 255\n",
        "test_imgs = test_imgs / 255\n",
        "\n",
        "n_train = train_imgs.shape[0]\n",
        "n_test = test_imgs.shape[0]\n",
        "n = n_train + n_test\n",
        "\n",
        "exp = 0\n",
        "random.seed(exp)\n",
        "torch.manual_seed(exp)\n",
        "np.random.seed(exp)\n",
        "\n",
        "#####################################################################\n",
        "# generate images\n",
        "train_quantiles = np.zeros((4, n_train))\n",
        "for i in range(n_train):\n",
        "    train_img_i = train_imgs[i, :]\n",
        "    train_img_i = train_img_i[train_img_i > 0]\n",
        "    train_quantiles[:, i] = np.quantile(train_img_i, [0, 0.25, 0.5, 0.75])\n",
        "\n",
        "train_q0 = np.tile(train_quantiles[0, :].reshape((n_train, 1)), (1, 784))\n",
        "train_q1 = np.tile(train_quantiles[1, :].reshape((n_train, 1)), (1, 784))\n",
        "train_q2 = np.tile(train_quantiles[2, :].reshape((n_train, 1)), (1, 784))\n",
        "train_q3 = np.tile(train_quantiles[3, :].reshape((n_train, 1)), (1, 784))\n",
        "\n",
        "train_p0 = np.zeros((n_train, 784))\n",
        "train_p1 = np.zeros((n_train, 784))\n",
        "train_p2 = np.zeros((n_train, 784))\n",
        "train_p3 = np.zeros((n_train, 784))\n",
        "\n",
        "train_p3[train_imgs >= train_q3] = train_imgs[train_imgs >= train_q3]\n",
        "train_p2[(train_imgs >= train_q2) & (train_imgs < train_q3)] = train_imgs[(train_imgs >= train_q2) & (train_imgs < train_q3)]\n",
        "train_p1[(train_imgs >= train_q1) & (train_imgs < train_q2)] = train_imgs[(train_imgs >= train_q1) & (train_imgs < train_q2)]\n",
        "train_p0[(train_imgs >= train_q0) & (train_imgs < train_q1)] = train_imgs[(train_imgs >= train_q0) & (train_imgs < train_q1)]\n",
        "\n",
        "train_predictors = np.zeros((n_train, 28*28*4))\n",
        "train_outcomes = train_imgs\n",
        "for i in range(n_train):\n",
        "    train_p0_i = train_p0[i, :].reshape((28, 28))\n",
        "    train_p1_i = train_p1[i, :].reshape((28, 28))\n",
        "    train_p2_i = train_p2[i, :].reshape((28, 28))\n",
        "    train_p3_i = train_p3[i, :].reshape((28, 28))\n",
        "    train_predictor_i = np.hstack((train_p0_i, train_p1_i, train_p2_i, train_p3_i))\n",
        "    train_predictors[i, :] = train_predictor_i.reshape(-1)\n",
        "\n",
        "test_quantiles = np.zeros((4, n_test))\n",
        "for i in range(n_test):\n",
        "    test_img_i = test_imgs[i, :]\n",
        "    test_img_i = test_img_i[test_img_i > 0]\n",
        "    test_quantiles[:, i] = np.quantile(test_img_i, [0, 0.25, 0.5, 0.75])\n",
        "\n",
        "\n",
        "test_q0 = np.tile(test_quantiles[0, :].reshape((n_test, 1)), (1, 784))\n",
        "test_q1 = np.tile(test_quantiles[1, :].reshape((n_test, 1)), (1, 784))\n",
        "test_q2 = np.tile(test_quantiles[2, :].reshape((n_test, 1)), (1, 784))\n",
        "test_q3 = np.tile(test_quantiles[3, :].reshape((n_test, 1)), (1, 784))\n",
        "\n",
        "test_p0 = np.zeros((n_test, 784))\n",
        "test_p1 = np.zeros((n_test, 784))\n",
        "test_p2 = np.zeros((n_test, 784))\n",
        "test_p3 = np.zeros((n_test, 784))\n",
        "\n",
        "test_p3[test_imgs >= test_q3] = test_imgs[test_imgs >= test_q3]\n",
        "test_p2[(test_imgs >= test_q2) & (test_imgs < test_q3)] = test_imgs[(test_imgs >= test_q2) & (test_imgs < test_q3)]\n",
        "test_p1[(test_imgs >= test_q1) & (test_imgs < test_q2)] = test_imgs[(test_imgs >= test_q1) & (test_imgs < test_q2)]\n",
        "test_p0[(test_imgs >= test_q0) & (test_imgs < test_q1)] = test_imgs[(test_imgs >= test_q0) & (test_imgs < test_q1)]\n",
        "\n",
        "test_predictors = np.zeros((n_test, 28*28*4))\n",
        "test_outcomes = test_imgs\n",
        "for i in range(n_test):\n",
        "    test_p0_i = test_p0[i, :].reshape((28, 28))\n",
        "    test_p1_i = test_p1[i, :].reshape((28, 28))\n",
        "    test_p2_i = test_p2[i, :].reshape((28, 28))\n",
        "    test_p3_i = test_p3[i, :].reshape((28, 28))\n",
        "    test_predictor_i = np.hstack((test_p0_i, test_p1_i, test_p2_i, test_p3_i))\n",
        "    test_predictors[i, :] = test_predictor_i.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92cd2a72-ca81-48b9-b58f-659e3f6b9aee",
      "metadata": {
        "id": "92cd2a72-ca81-48b9-b58f-659e3f6b9aee"
      },
      "source": [
        "### Generate grids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "616dcf88-c929-43c1-8e5a-27d022b6b30b",
      "metadata": {
        "id": "616dcf88-c929-43c1-8e5a-27d022b6b30b"
      },
      "outputs": [],
      "source": [
        "predictor_grids = bird_gp.generate_grids([28, 112])\n",
        "outcome_grids = bird_gp.generate_grids([28, 28])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc6ae86-11ce-450e-8ba1-93a9ee51c3e0",
      "metadata": {
        "tags": [],
        "id": "dbc6ae86-11ce-450e-8ba1-93a9ee51c3e0"
      },
      "source": [
        "### Create BIRD_GP object and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e43eab3-694e-434b-9d84-767c9d0b0835",
      "metadata": {
        "id": "6e43eab3-694e-434b-9d84-767c9d0b0835"
      },
      "outputs": [],
      "source": [
        "birdgp = bird_gp.BIRD_GP(predictor_grids = predictor_grids,\n",
        "                         outcome_grids = outcome_grids,\n",
        "                         predictor_L = 50,\n",
        "                         outcome_L = 50,\n",
        "                         svgd_b_lambda = 1e2, \n",
        "                         bf_predictor_steps = 10000,\n",
        "                         bf_outcome_steps = 10000,\n",
        "                         device = \"cpu\"\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b92b53-14c3-4c85-a126-3241363e9e96",
      "metadata": {
        "id": "06b92b53-14c3-4c85-a126-3241363e9e96"
      },
      "outputs": [],
      "source": [
        "birdgp.fit(train_predictors, train_outcomes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d739a671-df45-47c7-819d-0d140bf30e3e",
      "metadata": {
        "id": "d739a671-df45-47c7-819d-0d140bf30e3e"
      },
      "source": [
        "### Evaluation on training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7cd1480-1f51-4293-88d8-8221bca559ca",
      "metadata": {
        "tags": [],
        "id": "e7cd1480-1f51-4293-88d8-8221bca559ca"
      },
      "outputs": [],
      "source": [
        "train_pred = birdgp.predict_train()\n",
        "np.mean((train_pred - train_outcomes)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5554dc29-4e9d-4b35-b677-a7d4247e6db9",
      "metadata": {
        "id": "5554dc29-4e9d-4b35-b677-a7d4247e6db9"
      },
      "source": [
        "### Evaluation on testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c844dc82-0983-45d6-8c6f-d286d86440c1",
      "metadata": {
        "tags": [],
        "id": "c844dc82-0983-45d6-8c6f-d286d86440c1"
      },
      "outputs": [],
      "source": [
        "test_pred = birdgp.predict_test(test_predictors)\n",
        "np.mean((test_pred - test_outcomes)**2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torchenv",
      "language": "python",
      "name": "torchenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}