{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f",
   "metadata": {
    "id": "3fc3b1d6-9e73-41b9-b47f-0ee306f3925f"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import mnist\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "\n",
    "def generate_sign(n = 2000, size = 28, length_min = 13, length_max = 20, width_min = 3, width_max = 5):\n",
    "    center = math.floor(size / 2)\n",
    "    sign = np.random.choice((-1, 1), size = n)\n",
    "    length = np.random.choice(np.arange(length_min, length_max + 1), size = n)\n",
    "    width = np.random.choice(np.arange(width_min, width_max + 1), size = n)\n",
    "    start = np.random.choice(np.arange(4, size - length_max - 1), size = n) - center\n",
    "    x = np.tile(np.arange(size), size) - center\n",
    "    y = np.repeat(np.arange(size), size) - center\n",
    "    \n",
    "    sign_img = np.zeros((n, size**2))\n",
    "    for i in range(n):\n",
    "        sign_i = sign[i]\n",
    "        length_i = length[i]\n",
    "        width_i = width[i]\n",
    "        start_i = start[i]\n",
    "        minus_i = ((x >= start_i) &\n",
    "                   (x <= start_i + length_i) &\n",
    "                   (y >= - math.floor(width_i / 2)) &\n",
    "                   (y <= - math.floor(width_i / 2) + width_i))\n",
    "        if sign_i == -1:\n",
    "            sign_img[i, :] = minus_i * 1\n",
    "        else:\n",
    "            mid_i = (length_i + 2 * start_i) / 2\n",
    "            minus_i_2 = ((x >= math.floor(mid_i - width_i / 2)) &\n",
    "                         (x <= math.floor(mid_i + width_i / 2)) &\n",
    "                         (y >= -math.floor(length_i / 2)) &\n",
    "                         (y <= -math.floor(length_i / 2) + length_i))\n",
    "            sign_img[i, :] = (minus_i | minus_i_2) * 1\n",
    "    \n",
    "    sign_img[sign_img > 0] = 0.9 * sign_img[sign_img > 0] + np.random.normal(scale = 0.05, size = np.sum(sign_img > 0))\n",
    "    return sign_img, sign\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, predictors, labels):\n",
    "        self.labels = labels\n",
    "        self.predictors = predictors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.predictors[index, :]\n",
    "        y = self.labels[index, :]\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.linear = nn.Linear(32 * 7 * 7, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "x2PZbM4dz4cQ",
   "metadata": {
    "id": "x2PZbM4dz4cQ"
   },
   "outputs": [],
   "source": [
    "class RBDN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 5, stride = 1, padding = 2)\n",
    "        \n",
    "        self.convB11 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB12 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB21 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB22 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB31 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB32 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.deconvB1 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconvB2 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconvB3 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB1 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB2 = nn.MaxPool2d(2, 2)\n",
    "        self.poolB3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB2 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB3 = nn.MaxUnpool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv7 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv8 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv9 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.unpoolL = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconvL = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # B11\n",
    "        xB11 = F.relu(self.convB11(x1))\n",
    "        xB11 = self.poolB1(xB11)\n",
    "\n",
    "        # B21\n",
    "        xB21 = F.relu(self.convB21(xB11))\n",
    "        xB21 = self.poolB2(xB21)\n",
    "\n",
    "        # B3\n",
    "        xB3 = F.relu(self.convB31(xB21))\n",
    "        xB3 = self.poolB3(xB3)\n",
    "        xB3 = F.relu(self.convB32(xB3))\n",
    "        xB3 = self.unpoolB3(xB3)\n",
    "        xB3 = F.relu(self.deconvB3(xB3))\n",
    "\n",
    "        # B22\n",
    "        xB22 = torch.cat((xB21, xB3), axis = 1)\n",
    "        xB22 = F.relu(self.convB22(xB22))\n",
    "        xB22 = self.unpoolB2(xB22)\n",
    "        xB22 = F.relu(self.deconvB2(xB22))\n",
    "\n",
    "        # B12\n",
    "        xB12 = torch.cat((xB11, xB22), axis = 1)\n",
    "        xB12 = F.relu(self.convB12(xB12))\n",
    "        xB12 = self.unpoolB1(xB12)\n",
    "        xB12 = F.relu(self.deconvB1(xB12))\n",
    "\n",
    "        # conv 2-9\n",
    "        x = torch.cat((x1, xB12), axis = 1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        x = self.unpoolL(x)\n",
    "        x = self.deconvL(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507W2nRcQKWJ",
   "metadata": {
    "id": "507W2nRcQKWJ"
   },
   "outputs": [],
   "source": [
    "class RBDN(nn.Module):\n",
    "    def __init__(self, num_channels = 64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = num_channels, kernel_size = 5, stride = 1, padding = 2)\n",
    "        \n",
    "        self.convB11 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.convB12 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.deconvB1 = nn.ConvTranspose2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "        self.poolB1 = nn.MaxPool2d(2, 2, return_indices = True)\n",
    "\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.unpoolB1 = nn.MaxUnpool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = num_channels * 2, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv7 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv8 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv9 = nn.Conv2d(in_channels = num_channels, out_channels = num_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.unpoolL = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconvL = nn.ConvTranspose2d(in_channels = num_channels, out_channels = 1, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x1, idx1 = self.pool1(x1)\n",
    "\n",
    "        # B1\n",
    "        xB11 = F.relu(self.convB11(x1))\n",
    "        xB11, idxB1 = self.poolB1(xB11)\n",
    "        xB12 = F.relu(self.convB12(xB11))\n",
    "        xB12 = self.unpoolB1(xB12, indices = idxB1)\n",
    "        xB12 = F.relu(self.deconvB1(xB12))\n",
    "\n",
    "        # conv 2-9\n",
    "        x = torch.cat((x1, xB12), axis = 1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        x = self.unpoolL(x, indices = idx1)\n",
    "        x = self.deconvL(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fad42f-481e-4e7f-aa29-7441607064e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445313"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_channels = 64\n",
    "rbdn = RBDN(num_channels)\n",
    "sum([p.numel() for p in rbdn.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b",
   "metadata": {
    "id": "83b1b296-6c9d-4f80-99df-d97f4935c85b"
   },
   "outputs": [],
   "source": [
    "train_img, train_label, test_img, test_label = mnist.load()\n",
    "train_img = train_img / 255\n",
    "test_img = test_img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "31f8e68d-96bd-4e94-8c48-472fe76b1360",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6bf4d06b-7320-431c-ce34-dd050b5c084f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gxma/.conda/envs/torchgpu/lib/python3.9/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 1.0\n",
      "1 1.0 1.0\n",
      "2 1.0 1.0\n",
      "3 1.0 1.0\n",
      "4 1.0 1.0\n",
      "5 1.0 1.0\n",
      "6 1.0 1.0\n",
      "7 1.0 1.0\n",
      "8 1.0 1.0\n",
      "9 1.0 1.0\n",
      "10 1.0 1.0\n",
      "11 1.0 1.0\n",
      "12 1.0 1.0\n",
      "13 1.0 1.0\n",
      "14 1.0 1.0\n",
      "15 1.0 1.0\n",
      "16 1.0 1.0\n",
      "17 1.0 1.0\n",
      "18 1.0 1.0\n",
      "19 1.0 1.0\n",
      "20 1.0 1.0\n",
      "21 1.0 1.0\n",
      "22 1.0 1.0\n",
      "23 1.0 1.0\n",
      "24 1.0 1.0\n",
      "25 1.0 1.0\n",
      "26 1.0 1.0\n",
      "27 1.0 1.0\n",
      "28 1.0 1.0\n",
      "29 1.0 1.0\n",
      "30 1.0 1.0\n",
      "31 1.0 1.0\n",
      "32 1.0 1.0\n",
      "33 1.0 1.0\n",
      "34 1.0 1.0\n",
      "35 1.0 1.0\n",
      "36 1.0 1.0\n",
      "37 1.0 1.0\n",
      "38 1.0 1.0\n",
      "39 1.0 1.0\n",
      "40 1.0 1.0\n",
      "41 1.0 1.0\n",
      "42 1.0 1.0\n",
      "43 1.0 1.0\n",
      "44 1.0 1.0\n",
      "45 1.0 1.0\n",
      "46 1.0 1.0\n",
      "47 1.0 1.0\n",
      "48 1.0 1.0\n",
      "49 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_label_1_idx = np.where(train_label == 1)[0]\n",
    "train_label_2_idx = np.where(train_label == 2)[0]\n",
    "train_label_3_idx = np.where(train_label == 3)[0]\n",
    "test_label_1_idx = np.where(test_label == 1)[0]\n",
    "test_label_2_idx = np.where(test_label == 2)[0]\n",
    "test_label_3_idx = np.where(test_label == 3)[0]\n",
    "\n",
    "n = 2000\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "num_exp = 50\n",
    "result_mse = np.zeros((num_exp, 2))\n",
    "result_acc = np.zeros((num_exp, 2))\n",
    "for exp in range(num_exp):\n",
    "    random.seed(exp)\n",
    "    torch.manual_seed(exp)\n",
    "    np.random.seed(exp)\n",
    "    #####################################################################\n",
    "    # generate images\n",
    "    sign_img, sign = generate_sign(n = n)\n",
    "    train_sign = sign[0:n_train]\n",
    "    train_sign_img = sign_img[0:n_train, :]\n",
    "    test_sign = sign[n_train:n]\n",
    "    test_sign_img = sign_img[n_train:n, :]\n",
    "    train_1s = train_img[np.random.choice(train_label_1_idx, size = n_train, replace = False), :]\n",
    "    train_2s = train_img[np.random.choice(train_label_2_idx, size = n_train, replace = False), :]\n",
    "    test_1s = test_img[np.random.choice(test_label_1_idx, size = n_train, replace = False), :]\n",
    "    test_2s = test_img[np.random.choice(test_label_2_idx, size = n_train, replace = False), :]\n",
    "\n",
    "    train_predictors = np.zeros((n_train, 28*28*3))\n",
    "    train_outcomes = np.zeros((n_train, 28*28))\n",
    "    train_outcomes_padding = np.zeros((n_train, 28*28*3))\n",
    "    test_predictors = np.zeros((n_test, 28*28*3))\n",
    "    test_outcomes = np.zeros((n_test, 28*28))\n",
    "    test_outcomes_padding = np.zeros((n_test, 28*28*3))\n",
    "    train_outcomes_label = np.zeros(n_train)\n",
    "    test_outcomes_label = np.zeros(n_test)\n",
    "    for i in range(n_train):\n",
    "        train_1_i = train_1s[i, :].reshape((28, 28))\n",
    "        train_2_i = train_2s[i, :].reshape((28, 28))\n",
    "        train_sign_i = train_sign[i]\n",
    "        train_sign_img_i = train_sign_img[i, :].reshape((28, 28))\n",
    "        train_predictor_i = np.hstack((train_2_i, train_sign_img_i, train_1_i))\n",
    "        if train_sign_i == -1:\n",
    "            label_img_i = train_img[np.random.choice(train_label_1_idx, size = 1, replace = False), :]\n",
    "            train_outcomes_label[i] = 1\n",
    "        else:\n",
    "            label_img_i = train_img[np.random.choice(train_label_3_idx, size = 1, replace = False), :]\n",
    "            train_outcomes_label[i] = 3\n",
    "        train_predictors[i, :] = train_predictor_i.reshape(-1)\n",
    "        train_outcomes[i, :] = label_img_i\n",
    "        label_img_i = label_img_i.reshape((28, 28))\n",
    "        train_outcomes_padding[i, :] = np.hstack((np.zeros((28, 28)), label_img_i, np.zeros((28, 28)))).reshape(-1)\n",
    "\n",
    "    for i in range(n_test):\n",
    "        test_1_i = test_1s[i, :].reshape((28, 28))\n",
    "        test_2_i = test_2s[i, :].reshape((28, 28))\n",
    "        test_sign_i = test_sign[i]\n",
    "        test_sign_img_i = test_sign_img[i, :].reshape((28, 28))\n",
    "        test_predictor_i = np.hstack((test_2_i, test_sign_img_i, test_1_i))\n",
    "        if test_sign_i == -1:\n",
    "            label_img_i = test_img[np.random.choice(test_label_1_idx, size = 1, replace = False), :]\n",
    "            test_outcomes_label[i] = 1\n",
    "        else:\n",
    "            label_img_i = test_img[np.random.choice(test_label_3_idx, size = 1, replace = False), :]\n",
    "            test_outcomes_label[i] = 3\n",
    "        test_predictors[i, :] = test_predictor_i.reshape(-1)\n",
    "        test_outcomes[i, :] = label_img_i\n",
    "        label_img_i = label_img_i.reshape((28, 28))\n",
    "        test_outcomes_padding[i, :] = np.hstack((np.zeros((28, 28)), label_img_i, np.zeros((28, 28)))).reshape(-1)\n",
    "\n",
    "\n",
    "    np.savetxt(\"train_predictors.txt\", train_predictors)\n",
    "    np.savetxt(\"test_predictors.txt\", test_predictors)\n",
    "    np.savetxt(\"train_outcomes.txt\", train_outcomes)\n",
    "    np.savetxt(\"test_outcomes.txt\", test_outcomes)\n",
    "\n",
    "    #####################################################################\n",
    "    # train cnn mnist classifier\n",
    "    cnn = CNN().to(\"cuda\")\n",
    "    cnn_optimizer = torch.optim.Adam(cnn.parameters(), lr = 0.001)\n",
    "    cnn_loss = nn.functional.binary_cross_entropy\n",
    "\n",
    "    cnnX = torch.tensor(train_outcomes, dtype = torch.float32).reshape((n_train, 1, 28, 28)).to(\"cuda\")\n",
    "    cnny = torch.tensor(train_outcomes_label, dtype = torch.float32).reshape((n_train, 1)).to(\"cuda\")\n",
    "    cnny[cnny == 1] = 0\n",
    "    cnny[cnny == 3] = 1\n",
    "\n",
    "    cnn_dataset = Dataset(cnnX, cnny)\n",
    "    cnn_dataloader = torch.utils.data.DataLoader(cnn_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    cnn.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(cnn_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = cnn(X_batch)             \n",
    "            loss = cnn_loss(output, y_batch)\n",
    "\n",
    "            # clear gradients for this training step   \n",
    "            cnn_optimizer.zero_grad()           \n",
    "\n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            cnn_optimizer.step()\n",
    "\n",
    "    rbdn = RBDN(num_channels).to(\"cuda\")\n",
    "    rbdn_train_predictors = torch.tensor(train_predictors, dtype = torch.float32).reshape((n_train, 1, 28, 84)).to(\"cuda\")\n",
    "    rbdn_train_outcomes = torch.tensor(train_outcomes_padding, dtype = torch.float32).reshape((n_train, 1, 28, 84)).to(\"cuda\")\n",
    "    rbdn_loss = nn.functional.mse_loss\n",
    "    rbdn_optim = torch.optim.Adam(rbdn.parameters(), lr = 1e-3)\n",
    "\n",
    "    rbdn_dataset = Dataset(rbdn_train_predictors, rbdn_train_outcomes)\n",
    "    rbdn_dataloader = torch.utils.data.DataLoader(rbdn_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "    num_epochs = 50\n",
    "    rbdn.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (idx, (X_batch, y_batch)) in enumerate(rbdn_dataloader):\n",
    "            X_batch = X_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            output = rbdn(X_batch)             \n",
    "            loss = rbdn_loss(output, y_batch)\n",
    "\n",
    "            rbdn_optim.zero_grad()           \n",
    "            loss.backward()            \n",
    "            rbdn_optim.step()    \n",
    "    \n",
    "    rbdn_train_predictors = rbdn_train_predictors.to(\"cpu\")\n",
    "    rbdn = rbdn.to(\"cpu\")\n",
    "\n",
    "    rbdn_train_pred = rbdn(rbdn_train_predictors)\n",
    "    rbdn_test_pred = rbdn(torch.tensor(test_predictors, dtype = torch.float32).reshape((n_test, 1, 28, 84)))\n",
    "\n",
    "    rbdn_train_pred = rbdn_train_pred[:, :, :, 28:56]\n",
    "    rbdn_test_pred = rbdn_test_pred[:, :, :, 28:56]\n",
    "\n",
    "    cnn = cnn.to(\"cpu\")\n",
    "    result_acc[exp, 0] = sum( (cnn(rbdn_train_pred).detach().to(\"cpu\").numpy().reshape(-1) > 0.5) == (train_outcomes_label == 3) ) / n_train\n",
    "    result_acc[exp, 1] = sum( (cnn(rbdn_test_pred).detach().to(\"cpu\").numpy().reshape(-1) > 0.5) == (test_outcomes_label == 3) ) / n_test\n",
    "    result_mse[exp, 0] = np.mean((rbdn_train_pred.detach().to(\"cpu\").numpy().reshape((n_train, 784)) - train_outcomes)**2)\n",
    "    result_mse[exp, 1] = np.mean((rbdn_test_pred.detach().to(\"cpu\").numpy().reshape((n_test, 784)) - test_outcomes)**2)\n",
    "\n",
    "    print(exp, result_acc[exp, 0], result_acc[exp, 1])\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    np.savetxt(\"result_mse_rbdn.txt\", result_mse)\n",
    "    np.savetxt(\"result_acc_rbdn.txt\", result_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ROh1_x4fSseH",
   "metadata": {
    "id": "ROh1_x4fSseH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "digits-rbdn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
